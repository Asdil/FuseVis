{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the pytorch implementation of the deep learning model proposed in the paper 'Generating a Fusion Image: One's Identity and Another's Shape '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models.vgg import vgg19\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from skimage import img_as_ubyte\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision      # dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "import argparse\n",
    "import glob\n",
    "import imageio\n",
    "from skimage import color\n",
    "import numpy\n",
    "import natsort\n",
    "import scipy\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "import pprint\n",
    "from scipy.ndimage import correlate\n",
    "from scipy.ndimage.filters import gaussian_gradient_magnitude\n",
    "import torchvision.datasets as dset\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import os.path\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import tkinter.font as tkFont\n",
    "from PIL import ImageTk, Image\n",
    "import pylab\n",
    "import cv2\n",
    "import h5py\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11811160064\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(torch.cuda.get_device_properties(0).total_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the hyperparameters\n",
    "image_length = 256\n",
    "image_width  = 256\n",
    "mr_channels  = 1\n",
    "gray_channels = 1\n",
    "pet_channels = 4    \n",
    "rgb_channels = 3     \n",
    "batch_size   = 1\n",
    "EPOCH = 50\n",
    "learning_rate = 0.002 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the train mri data\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/Training/MRI')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/Training/MRI')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "train_mri = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    train_mri[i,:,:] =(imageio.imread(data[i]))\n",
    "    train_mri[i,:,:] =(train_mri[i,:,:] - np.min(train_mri[i,:,:])) / (np.max(train_mri[i,:,:]) - np.min(train_mri[i,:,:]))\n",
    "    train_mri[i,:,:] = np.float32(train_mri[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "train_mri = np.expand_dims(train_mri,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 1, 256, 256)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify the shape matches the pytorch standard\n",
    "train_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([272, 1, 256, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the MRI training data to pytorch tensor\n",
    "train_mri_tensor = torch.from_numpy(train_mri).float()\n",
    "train_mri_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the train pet data\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/Training/PET')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/Training/PET')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "train_other = np.zeros((len(data),image_width,image_length,pet_channels),dtype=float)\n",
    "train_pet = np.zeros((len(data),image_width,image_length),dtype=float)\n",
    "for i in range(len(data)):\n",
    "    train_other[i,:,:,:] =(imageio.imread(data[i]))\n",
    "    train_pet[i,:,:] = 0.2989 * train_other[i,:,:,0] + 0.5870 *  train_other[i,:,:,1]  + 0.1140 * train_other[i,:,:,2]\n",
    "    train_pet[i,:,:] =(train_pet[i,:,:] - np.min(train_pet[i,:,:])) / (np.max(train_pet[i,:,:]) - np.min(train_pet[i,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand the dimension to add the channel\n",
    "train_pet = np.expand_dims(train_pet,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 1, 256, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify the shape matches the pytorch standard\n",
    "train_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([272, 1, 256, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the PET training data to pytorch tensor\n",
    "train_pet_tensor = torch.from_numpy(train_pet).float()\n",
    "train_pet_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the generator network\n",
    "# 3x3 convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        # if torch.cuda.is_available():\n",
    "        \t# residual = torch.cuda.FloatTensor(residual)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# Generator Definition\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, block):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.conv1_x = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding = 1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(2))\n",
    "        \n",
    "        self.conv2_x = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, padding = 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(2))\n",
    "\n",
    "        self.conv3_x = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, 3, padding = 1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv1_y = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding = 1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(2))\n",
    "        \n",
    "        self.conv2_y = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, padding = 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AvgPool2d(2))\n",
    "\n",
    "        self.conv3_y = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, 3, padding = 1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True))      \n",
    "            \n",
    "        # 2 Residual Blocks for Identity Image\n",
    "        self.block1_x = block(16, 16)\n",
    "#         downsample_x = nn.Sequential(conv3x3(16, 1, 1), nn.BatchNorm2d(1))\n",
    "#         self.block2_x = block(16, 1, 1, downsample_x)\n",
    "        self.block2_x = block(16, 16)\n",
    "\n",
    "        # 2 Residual Blocks for Shape Image\n",
    "        self.block1_y = block(16, 16)\n",
    "#         downsample_y = nn.Sequential(conv3x3(16, 1, 1), nn.BatchNorm2d(1))\n",
    "#         self.block2_y = block(16, 1, 1, downsample_y)\n",
    "        self.block2_y = block(16, 16)\n",
    "\n",
    "        # 2 Residual Blocks for Combined(concat) image\n",
    "        downsample1_concat = nn.Sequential(conv3x3(32, 16, 1), nn.BatchNorm2d(16))\n",
    "        self.block1_concat = block(32, 16, 1, downsample1_concat)\n",
    "\n",
    "        self.block2_concat = block(16, 16)\n",
    "        \n",
    "        # Upsampling layers\n",
    "                \n",
    "        self.upsample1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners = True),\n",
    "            nn.ConvTranspose2d(16, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.upsample2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.ConvTranspose2d(32, 1, 3, padding=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        x = self.conv1_x(x)\n",
    "        x = self.conv2_x(x)\n",
    "        x = self.conv3_x(x)\n",
    "        x = self.block1_x(x)\n",
    "        x = self.block2_x(x)\n",
    "        \n",
    "        y = self.conv1_y(y)\n",
    "        y = self.conv2_y(y)\n",
    "        y = self.conv3_y(y)\n",
    "        y = self.block1_y(y)\n",
    "        y = self.block2_y(y)\n",
    "        \n",
    "        concat_result = torch.zeros([x.shape[0], x.shape[1] * 2, x.shape[2], x.shape[3]], dtype=x.dtype)\n",
    "#         print(x.shape, y.shape, concat_result.shape)\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[1]):\n",
    "                concat_result[i][j] = x[i][j]\n",
    "                concat_result[i][j + x.shape[1]] = y[i][j]\n",
    "        if torch.cuda.is_available():\n",
    "        \tconcat_result = concat_result.cuda()\n",
    "        concat_result = self.block1_concat(concat_result)\n",
    "        concat_result = self.block2_concat(concat_result)\n",
    "        \n",
    "        upsampled_1 = self.upsample1(concat_result)\n",
    "        upsampled_2 = self.upsample2(upsampled_1)\n",
    "        #print(upsampled_2.shape)\n",
    "        return upsampled_2\n",
    "\n",
    "gen = Generator(ResidualBlock)\n",
    "gen = gen.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLayerDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, use_sigmoid=False):\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        \n",
    "        use_bias = norm_layer\n",
    "\n",
    "        kw = 3\n",
    "        padw = 1\n",
    "        sequence = []\n",
    "        self.initial_conv = nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw)\n",
    "        self.initial_relu = nn.LeakyReLU(0.2, True)\n",
    "        \n",
    "    \n",
    "        ndf = 128\n",
    "        \n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2**n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
    "                          kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2**n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult,\n",
    "                      kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]\n",
    "\n",
    "        if use_sigmoid:\n",
    "            sequence += [nn.Sigmoid()]\n",
    "\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(8)\n",
    "    def forward(self, x, y):\n",
    "        x = self.initial_relu(self.initial_conv(x))\n",
    "        y = self.initial_relu(self.initial_conv(y))\n",
    "        \n",
    "        concat_fmap = torch.zeros([x.shape[0], 2 * x.shape[1], x.shape[2], x.shape[3]], dtype=x.dtype)\n",
    "#         print(x.shape, y.shape, concat_result.shape)\n",
    "        for i in range(x.shape[0]):\n",
    "            for j in range(x.shape[1]):\n",
    "                concat_fmap[i][j] = x[i][j]\n",
    "                concat_fmap[i][j + 64] = y[i][j]\n",
    "        if torch.cuda.is_available():\n",
    "        \tconcat_fmap = concat_fmap.cuda()\n",
    "        op = self.model(concat_fmap)\n",
    "        #op_neg = - op\n",
    "        #op_neg = self.maxpool(op_neg)\n",
    "        #op_pooled = -op_neg\n",
    "        #print(op_pooled.shape)\n",
    "        return op\n",
    "    \n",
    "disc = NLayerDiscriminator(1)\n",
    "disc = disc.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the optimizers and loss functions \n",
    "gen_optimizer = torch.optim.Adam(gen.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
    "disc_optimizer = torch.optim.SGD(disc.parameters(), lr=0.1, momentum=0.9)   # optimize all cnn parameters\n",
    "l2_loss   = nn.MSELoss() #MSEloss\n",
    "BCELoss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0],step: [100], mri_ssim_loss: [0.30391604], pet_ssim_loss: [0.28312999], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 0],step: [200], mri_ssim_loss: [0.63707697], pet_ssim_loss: [0.56727916], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 1],step: [300], mri_ssim_loss: [0.40963846], pet_ssim_loss: [0.39040864], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 1],step: [400], mri_ssim_loss: [0.24196112], pet_ssim_loss: [0.17909455], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 1],step: [500], mri_ssim_loss: [0.84910542], pet_ssim_loss: [0.40461642], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 2],step: [600], mri_ssim_loss: [0.59480214], pet_ssim_loss: [0.31676787], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 2],step: [700], mri_ssim_loss: [0.40600610], pet_ssim_loss: [0.31424713], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 2],step: [800], mri_ssim_loss: [0.31627047], pet_ssim_loss: [0.18446946], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 3],step: [900], mri_ssim_loss: [0.31739110], pet_ssim_loss: [0.16804481], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 3],step: [1000], mri_ssim_loss: [0.50051975], pet_ssim_loss: [0.36397552], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 4],step: [1100], mri_ssim_loss: [0.32799953], pet_ssim_loss: [0.19387078], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 4],step: [1200], mri_ssim_loss: [0.25821579], pet_ssim_loss: [0.09350079], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 4],step: [1300], mri_ssim_loss: [0.37011236], pet_ssim_loss: [0.14389098], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 5],step: [1400], mri_ssim_loss: [0.48540580], pet_ssim_loss: [0.24838442], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 5],step: [1500], mri_ssim_loss: [0.19768286], pet_ssim_loss: [0.12451476], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 5],step: [1600], mri_ssim_loss: [0.39919519], pet_ssim_loss: [0.12419337], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 6],step: [1700], mri_ssim_loss: [0.54027444], pet_ssim_loss: [0.15920073], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 6],step: [1800], mri_ssim_loss: [0.39419383], pet_ssim_loss: [0.08640790], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 6],step: [1900], mri_ssim_loss: [0.38001871], pet_ssim_loss: [0.11654389], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 7],step: [2000], mri_ssim_loss: [0.29628766], pet_ssim_loss: [0.08414930], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 7],step: [2100], mri_ssim_loss: [0.54316151], pet_ssim_loss: [0.12975305], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 8],step: [2200], mri_ssim_loss: [0.40696150], pet_ssim_loss: [0.16096449], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 8],step: [2300], mri_ssim_loss: [0.23944086], pet_ssim_loss: [0.06873059], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 8],step: [2400], mri_ssim_loss: [0.78157145], pet_ssim_loss: [0.15153891], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 9],step: [2500], mri_ssim_loss: [0.34125119], pet_ssim_loss: [0.16639107], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 9],step: [2600], mri_ssim_loss: [0.26182890], pet_ssim_loss: [0.09946132], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 9],step: [2700], mri_ssim_loss: [0.33645797], pet_ssim_loss: [0.09838325], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [10],step: [2800], mri_ssim_loss: [0.31433153], pet_ssim_loss: [0.10023904], gen_loss: [nan], disc_loss: [nan]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d3a7c825af9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m#update the discriminator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mdisc_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                 \u001b[1;31m# backpropagation, compute gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mdisc_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                \u001b[1;31m# apply gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# perform the training\n",
    "counter = 0\n",
    "Tensor = torch.cuda.FloatTensor if device else torch.FloatTensor\n",
    "# Adversarial ground truths\n",
    "one = Tensor(np.ones((1,1,32,32)))\n",
    "zero = Tensor(np.zeros((1,1,32,32)))\n",
    "\n",
    "start_time = time.time()\n",
    "lamda = 1\n",
    "ep_ssim_mri_loss = []\n",
    "ep_ssim_pet_loss = []\n",
    "ep_adv_loss = []\n",
    "ep_disc_loss = []\n",
    "ep_gen_loss =[]\n",
    "for epoch in range(EPOCH):\n",
    "    ssim_mri_Loss = []\n",
    "    ssim_pet_Loss   = []\n",
    "    adv_Loss = []\n",
    "    gen_Loss = []\n",
    "    disc_Loss = []\n",
    "    #run batch images\n",
    "    batch_idxs = 272 // batch_size\n",
    "    for idx in range(0, batch_idxs):\n",
    "        #ge tthe mri and pet batches\n",
    "        b_x = train_mri_tensor[idx*batch_size : (idx+1)*batch_size,:,:,:].to(device)\n",
    "        b_y = train_pet_tensor[idx*batch_size : (idx+1)*batch_size,:,:,:].to(device)\n",
    "        counter += 1\n",
    "        \n",
    "        #clear the generator gradients\n",
    "        gen_optimizer.zero_grad()    \n",
    "\n",
    "        #get a fused image from generator\n",
    "        output = gen(b_x,b_y)               # gen output\n",
    "        \n",
    "        #feed the fused image into the discriminator 1 and 2\n",
    "        fused_disc_score = disc(output,b_y)\n",
    "        \n",
    "        #define the generator loss\n",
    "        ssim_loss_mri = 1 - ssim(output, b_x,data_range=1)\n",
    "        ssim_loss_pet = 1 - ssim(output, b_y,data_range=1)\n",
    "        ssim_loss = ssim_loss_mri + ssim_loss_pet\n",
    "        adv_loss = BCELoss(fused_disc_score,one)\n",
    "        gen_loss = ssim_loss + adv_loss\n",
    "        \n",
    "        #update the generator\n",
    "        gen_loss.backward(retain_graph=True)                 # backpropagation, compute gradients\n",
    "        gen_optimizer.step()                # apply gradients\n",
    "        \n",
    "        #clear the discriminator gradients\n",
    "        disc_optimizer.zero_grad()  \n",
    "        \n",
    "        #feed the MRI image and PET images into the discriminator 1 and 2 respectively\n",
    "        mri_disc_score = disc(b_x, b_y)\n",
    "        \n",
    "        #define the discriminator loss\n",
    "        disc_real = BCELoss(mri_disc_score,one)\n",
    "        disc_fake = BCELoss(fused_disc_score,zero)\n",
    "        disc_loss = disc_real + disc_fake\n",
    "        \n",
    "        #update the discriminator\n",
    "        disc_loss.backward()                 # backpropagation, compute gradients\n",
    "        disc_optimizer.step()                # apply gradients  \n",
    "\n",
    "        #store all the loss values at each epoch\n",
    "        ssim_mri_Loss.append(ssim_loss_mri.item())\n",
    "        ssim_pet_Loss.append(ssim_loss_pet.item())\n",
    "        gen_Loss.append(gen_loss.item())\n",
    "        disc_Loss.append(disc_loss.item())\n",
    "        if counter % 100 == 0:\n",
    "            print(\"Epoch: [%2d],step: [%2d], mri_ssim_loss: [%.8f], pet_ssim_loss: [%.8f], gen_loss: [%.8f], disc_loss: [%.8f]\" \n",
    "            %(epoch, counter, ssim_loss_mri, ssim_loss_pet, gen_loss, disc_loss))\n",
    "    \n",
    "    av_ssim_mri_loss = np.average(ssim_mri_Loss)\n",
    "    ep_ssim_mri_loss.append(av_ssim_mri_loss)\n",
    "    \n",
    "    av_ssim_pet_loss = np.average(ssim_pet_Loss)\n",
    "    ep_ssim_pet_loss.append(av_ssim_pet_loss)\n",
    "    \n",
    "    av_gen_loss = np.average(gen_Loss)\n",
    "    ep_gen_loss.append(av_gen_loss)\n",
    "    \n",
    "    av_disc_loss = np.average(disc_Loss)\n",
    "    ep_disc_loss.append(av_disc_loss)\n",
    "    \n",
    "    if(epoch == EPOCH -1):\n",
    "        #Save a checkpoint\n",
    "        torch.save(gen, 'C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/One Identity Another Shape/checkpoint_gen.pth') \n",
    "        torch.save(disc, 'C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/One Identity Another Shape/checkpoint_disc.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_loss_mri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test input MRI dataset\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/MRI/')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/MRI/')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "test_mri = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    test_mri[i,:,:] =(imageio.imread(data[i]))\n",
    "    test_mri[i,:,:] =(test_mri[i,:,:] - np.min(test_mri[i,:,:])) / (np.max(test_mri[i,:,:]) - np.min(test_mri[i,:,:]))\n",
    "    test_mri[i,:,:] = np.float32(test_mri[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "test_mri = np.expand_dims(test_mri,axis=1)\n",
    "#verify the shape matches the pytorch standard\n",
    "test_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the test mri image\n",
    "#test_mri = test_mri[0,:,:,:]\n",
    "#test_mri = np.expand_dims(test_mri,axis=0)\n",
    "plt.imshow(test_mri[0,0,:,:],'gray')\n",
    "#plt.savefig('MRI.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the MRI Testing data to pytorch tensor\n",
    "test_mri_tensor = torch.from_numpy(test_mri).float()\n",
    "print(test_mri_tensor.shape)\n",
    "test_mri_tensor.requires_grad =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test input PET dataset\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/PET/')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/PET/')\n",
    "data = glob.glob(os.path.join(dataset, \"*.png\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "test_pet = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    test_pet[i,:,:] =(imageio.imread(data[i]))\n",
    "    test_pet[i,:,:] =(test_pet[i,:,:] - np.min(test_pet[i,:,:])) / (np.max(test_pet[i,:,:]) - np.min(test_pet[i,:,:]))\n",
    "    test_pet[i,:,:] = np.float32(test_pet[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "test_pet = np.expand_dims(test_pet,axis=1)\n",
    "#verify the shape matches the pytorch standard\n",
    "test_pet.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the test pet image\n",
    "test_pet = test_pet[2,:,:,:]\n",
    "test_pet = np.expand_dims(test_pet,axis=0)\n",
    "plt.imshow(test_pet[0,0,:,:],'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_pet[0,0,:,:],'gray')\n",
    "#plt.savefig('PET.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the MRI Testing data to pytorch tensor\n",
    "test_pet_tensor = torch.from_numpy(test_pet).float()\n",
    "print(test_pet_tensor.shape)\n",
    "test_pet_tensor.requires_grad =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn =torch.load('C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/FunFuseAn/checkpoint.pth')\n",
    "cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted the fused image\n",
    "fused = cnn(test_mri_tensor, test_pet_tensor)\n",
    "fused_numpy = fused.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the output image\n",
    "plt.imshow(fused_numpy[0,0,:,:],'gray')\n",
    "#plt.savefig('Fused.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imageio.imwrite('C:/Users/horan/Desktop/Suraka/Fused/Fused.png',np.uint8(cv2.normalize(fused_numpy[0,0,:,:], None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the guidance image for MRI and PET wrt to the fused image\n",
    "time1 = time.time()\n",
    "count = 0 \n",
    "guide_fuse_mri = np.zeros((256,256),dtype=float)\n",
    "guide_fuse_pet = np.zeros((256,256),dtype=float)\n",
    "\n",
    "for y_coord in range(0,256):\n",
    "    for x_coord in range(0,256):\n",
    "        jacob_fuse_mri = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_mri_tensor, retain_graph=True, create_graph=True)[0]\n",
    "        jacob_numpy_mri = np.squeeze(jacob_fuse_mri.data.cpu().numpy())  \n",
    "        guide_fuse_mri[y_coord,x_coord] = jacob_numpy_mri[y_coord,x_coord]\n",
    "        jacob_fuse_pet = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_pet_tensor, retain_graph=True, create_graph=True)[0]\n",
    "        jacob_numpy_pet = np.squeeze(jacob_fuse_pet.data.cpu().numpy())  \n",
    "        guide_fuse_pet[y_coord,x_coord] = jacob_numpy_pet[y_coord,x_coord]\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print('Count is %d' %count)\n",
    "time2 = time.time()\n",
    "print('Time taken to compute is %d seconds' %(time2-time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "plt.colorbar()\n",
    "#plt.savefig('Jacob_Fused_MRI.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guide_fuse_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "#plt.colorbar()\n",
    "#plt.savefig('Jacob_Fused_PET.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guide_fuse_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(fused_RGB)\n",
    "#plt.savefig('Fused_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(mri_RGB)\n",
    "#plt.savefig('MRI_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(pet_RGB)\n",
    "#plt.savefig('PET_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5f = h5py.File('C:/Users/horan/Desktop/Suraka/Jacobian_MRI.h5', 'w')\n",
    "#h5f.create_dataset('MRI_dataset', data=guide_fuse_mri)\n",
    "#h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5f = h5py.File('C:/Users/horan/Desktop/Suraka/Jacobian_PET.h5', 'w')\n",
    "#h5f.create_dataset('PET_dataset', data=guide_fuse_pet)\n",
    "#h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/H5 Files/Jacobian_MRI.h5', 'r')\n",
    "guide_fuse_mri =  np.array(hf.get('MRI_dataset'))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/H5 Files/Jacobian_PET.h5', 'r')\n",
    "guide_fuse_pet =  np.array(hf.get('PET_dataset'))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define overlay images\n",
    "fused_RGB = np.zeros((256,256,3),dtype=float)\n",
    "mri_RGB   = np.zeros((256,256,3),dtype=float)\n",
    "pet_RGB   = np.zeros((256,256,3),dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_RGB[:,:,0]  = guide_fuse_mri \n",
    "fused_RGB[:,:,1]  = guide_fuse_pet \n",
    "fused_RGB[:,:,2]  = fused_numpy[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fused_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_RGB[:,:,0]  = guide_fuse_mri\n",
    "mri_RGB[:,:,1]  = guide_fuse_pet \n",
    "mri_RGB[:,:,2]  = test_mri[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mri_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_RGB[:,:,0]  = guide_fuse_mri\n",
    "pet_RGB[:,:,1]  = guide_fuse_pet \n",
    "pet_RGB[:,:,2]  = test_pet[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pet_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the window\n",
    "root = Tk()  \n",
    "root.title('Visualisation of fusion networks')\n",
    "root.configure(background='white')\n",
    "\n",
    "\n",
    "#Label the images\n",
    "#fontStyle = tkFont.Font(family=\"Lucida Grande\", size=15)\n",
    "#w1 = tk.Label(root, bg='white', font=fontStyle, text=\"Fused Image\")\n",
    "#w1.grid(row=0, column=1)\n",
    "#w1.pack()\n",
    "\n",
    "#define the frame\n",
    "canvasframe = Frame(root)  # define Input and output frame\n",
    "buttonframe = Frame(root)  # define button frame\n",
    "canvasframe.pack()  # pack the Input and Output frame\n",
    "buttonframe.pack()  # pack the button frame\n",
    "\n",
    "\n",
    "#define the canvas\n",
    "canvas = Canvas(canvasframe, width=1800, height=920, bg = 'white')\n",
    "canvas.grid(row=0, column=0)\n",
    "\n",
    "#Insert fused image to the canvas\n",
    "img_fused = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/Fused/Fused.png\") # load the image\n",
    "canvas.create_image(0, 0, image=img_fused, anchor=NW)\n",
    "\n",
    "#Insert MRI image to the canvas\n",
    "img_mri = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/MRI/MRI.gif\") # load the image\n",
    "canvas.create_image(620, 0, image=img_mri, anchor=NW)\n",
    "\n",
    "#Insert PET image to the canvas\n",
    "img_pet = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/PET/3.png\") # load the image\n",
    "canvas.create_image(1240, 0, image=img_pet, anchor=NW)\n",
    "\n",
    "def start_mouseover():  # function called when user clicks the button \n",
    "    # link the function to the left-mouse-click event\n",
    "    canvas.bind(\"<B1-Motion>\", Coordinates)\n",
    "\n",
    "def Coordinates(event): # function called when left-mouse-button is clicked with a mouseover\n",
    "    x_coord = event.x  # save x and y coordinates selected by the user   \n",
    "    y_coord = event.y\n",
    "    print('mouse position is at' + '(' + str(y_coord) + ',' + str(x_coord) + ')', end='\\r')\n",
    "    #display the output MRI Jacobian image\n",
    "    #img_MR_out = ImageTk.PhotoImage(file ='C:/Users/cgvadmin/Desktop/Suraka/Fused_MRI/im_' + str(y_coord) + '_' + str(x_coord) + '.png') # load the image\n",
    "    jacobian_fuse_mri = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_mri_tensor, retain_graph=True, create_graph=True)[0]\n",
    "    jacobian_fuse_pet = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_pet_tensor, retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    jacob_val_mri = np.squeeze(jacobian_fuse_mri.data.cpu().numpy())    \n",
    "    jacob_val_pet = np.squeeze(jacobian_fuse_pet.data.cpu().numpy())\n",
    "    \n",
    "    x_mri = np.asarray(np.where(np.any(jacob_val_mri, axis = 0)))\n",
    "    y_mri = np.asarray(np.where(np.any(jacob_val_mri, axis = 1)))\n",
    "    minx_mri, maxx_mri, miny_mri, maxy_mri = np.min(x_mri), np.max(x_mri), np.min(y_mri), np.max(y_mri)  #return min and max coordinates\n",
    "    zoom_im_mri = jacob_val_mri[miny_mri:maxy_mri,minx_mri:maxx_mri] \n",
    "    \n",
    "    x_pet = np.asarray(np.where(np.any(jacob_val_pet, axis = 0)))\n",
    "    y_pet = np.asarray(np.where(np.any(jacob_val_pet, axis = 1)))\n",
    "    minx_pet, maxx_pet, miny_pet, maxy_pet = np.min(x_pet), np.max(x_pet), np.min(y_pet), np.max(y_pet)  #return min and max coordinates\n",
    "    zoom_im_pet = jacob_val_pet[miny_pet:maxy_pet,minx_pet:maxx_pet] \n",
    "    \n",
    "    plt.imshow(fused_numpy[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom Fused')\n",
    "    plt.savefig('foo11.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out11 = ImageTk.PhotoImage(file ='foo11.png')\n",
    "    canvas.create_image(320,0,image=im_out11,anchor=NW)\n",
    "    canvas.image11 = im_out11\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(test_mri[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom MRI')\n",
    "    plt.savefig('foo12.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out12 = ImageTk.PhotoImage(file ='foo12.png')\n",
    "    canvas.create_image(950,0,image=im_out12,anchor=NW)\n",
    "    canvas.image12 = im_out12\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(test_pet[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom PET')\n",
    "    plt.savefig('foo13.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out13 = ImageTk.PhotoImage(file ='foo13.png')\n",
    "    canvas.create_image(1500,0,image=im_out13,anchor=NW)\n",
    "    canvas.image13 = im_out13\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(jacob_val_mri,cmap='viridis', aspect ='equal')\n",
    "    plt.title('Fused wrt MRI')\n",
    "    plt.savefig('foo1.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out1 = ImageTk.PhotoImage(file ='foo1.png')\n",
    "    canvas.create_image(0,320,image=im_out1,anchor=NW)\n",
    "    canvas.image1 = im_out1\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    #f.add_subplot(1,5,2)\n",
    "    plt.imshow(zoom_im_mri,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Zoomed (Fused wrt MRI)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('foo2.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out2 = ImageTk.PhotoImage(file ='foo2.png')\n",
    "    canvas.create_image(280,320,image=im_out2,anchor=NW)\n",
    "    canvas.image2 = im_out2\n",
    "    #plt.tight_layout()\n",
    "    #divider = make_axes_locatable(plt)\n",
    "    #cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    #plt.colorbar(cax=cax)\n",
    "    \n",
    "    #f.add_subplot(1,5,3)\n",
    "    plt.xlim(0,0.7)\n",
    "    plt.ylim(0,0.7)\n",
    "    plt.plot(jacob_val_mri[y_coord,x_coord],jacob_val_pet[y_coord,x_coord],'-ro')\n",
    "    plt.xlabel('MRI pixel score (Fused wrt MRI)')\n",
    "    plt.ylabel('PET pixel score (Fused wrt PET)')\n",
    "    plt.title('Mouse position at: (' + str(y_coord) + ',' + str(x_coord) + ')')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.draw()\n",
    "    plt.savefig('foo3.png', bbox_inches = 'tight',pad_inches = 0.1)\n",
    "    plt.close()\n",
    "    im_out3 = ImageTk.PhotoImage(file ='foo3.png')\n",
    "    canvas.create_image(600,320,image=im_out3,anchor=NW)\n",
    "    canvas.image3 = im_out3\n",
    "    \n",
    "    #f.add_subplot(1,5,4)\n",
    "    plt.imshow(jacob_val_pet,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Fused wrt PET')\n",
    "    plt.savefig('foo4.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out4 = ImageTk.PhotoImage(file ='foo4.png')\n",
    "    canvas.create_image(900,320,image=im_out4,anchor=NW)\n",
    "    canvas.image4 = im_out4\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    #f.add_subplot(1,5,5)\n",
    "    plt.imshow(zoom_im_pet,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Zoomed (Fused wrt PET)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('foo5.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out5 = ImageTk.PhotoImage(file ='foo5.png')\n",
    "    canvas.create_image(1180,320,image=im_out5,anchor=NW)\n",
    "    canvas.image5 = im_out5\n",
    "\n",
    "    plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "    plt.title('Fused wrt MRI')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('foo6.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out6 = ImageTk.PhotoImage(file ='foo6.png')\n",
    "    canvas.create_image(0,650,image=im_out6,anchor=NW)\n",
    "    canvas.image6 = im_out6\n",
    "    \n",
    "    plt.imshow(fused_RGB)\n",
    "    plt.savefig('foo8.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out8 = ImageTk.PhotoImage(file ='foo8.png')\n",
    "    canvas.create_image(300,650,image=im_out8,anchor=NW)\n",
    "    canvas.image8 = im_out8\n",
    "    \n",
    "    plt.imshow(mri_RGB)\n",
    "    plt.savefig('foo9.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out9 = ImageTk.PhotoImage(file ='foo9.png')\n",
    "    canvas.create_image(600,650,image=im_out9,anchor=NW)\n",
    "    canvas.image9 = im_out9\n",
    "    \n",
    "    plt.imshow(pet_RGB)\n",
    "    plt.savefig('foo10.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out10 = ImageTk.PhotoImage(file ='foo10.png')\n",
    "    canvas.create_image(900,650,image=im_out10,anchor=NW)\n",
    "    canvas.image10 = im_out10\n",
    "    \n",
    "    plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('foo7.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out7 = ImageTk.PhotoImage(file ='foo7.png')\n",
    "    canvas.create_image(1200,650,image=im_out7,anchor=NW)\n",
    "    canvas.image7 = im_out7\n",
    "    \n",
    "    radius = 5\n",
    "    i = canvas.create_oval(x_coord-radius, y_coord-radius, x_coord+radius, y_coord+radius, fill = 'red')\n",
    "    canvas.after(20,canvas.delete,i)\n",
    "\n",
    "# insert button to the middleframe and link it to \"Start Mouseover\"\n",
    "button_start_mouseover = Button(buttonframe, text=\"Start Mouseover\",command=start_mouseover)\n",
    "button_start_mouseover.grid(row=1, column=0, pady=0)\n",
    "\n",
    "\n",
    "root.mainloop()  #keep the GUI open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
