{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models.vgg import vgg19\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from skimage import img_as_ubyte\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision      # dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "import argparse\n",
    "import glob\n",
    "import imageio\n",
    "from skimage import color\n",
    "import numpy\n",
    "import natsort\n",
    "import scipy\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "import pprint\n",
    "from scipy.ndimage import correlate\n",
    "from scipy.ndimage.filters import gaussian_gradient_magnitude\n",
    "import torchvision.datasets as dset\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import os.path\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import tkinter.font as tkFont\n",
    "from PIL import ImageTk, Image\n",
    "import pylab\n",
    "import cv2\n",
    "import h5py\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11811160064\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(torch.cuda.get_device_properties(0).total_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the hyperparameters\n",
    "image_length = 256\n",
    "image_width  = 256\n",
    "mr_channels  = 1\n",
    "gray_channels = 1\n",
    "pet_channels = 4    \n",
    "rgb_channels = 3     \n",
    "batch_size   = 1\n",
    "EPOCH = 50\n",
    "learning_rate = 0.002 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the train mri data\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/Training/MRI')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/Training/MRI')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "train_mri = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    train_mri[i,:,:] =(imageio.imread(data[i]))\n",
    "    train_mri[i,:,:] =(train_mri[i,:,:] - np.min(train_mri[i,:,:])) / (np.max(train_mri[i,:,:]) - np.min(train_mri[i,:,:]))\n",
    "    train_mri[i,:,:] = np.float32(train_mri[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "train_mri = np.expand_dims(train_mri,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 1, 256, 256)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify the shape matches the pytorch standard\n",
    "train_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([272, 1, 256, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the MRI training data to pytorch tensor\n",
    "train_mri_tensor = torch.from_numpy(train_mri).float()\n",
    "train_mri_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the train pet data\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/Training/PET')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/Training/PET')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "train_other = np.zeros((len(data),image_width,image_length,pet_channels),dtype=float)\n",
    "train_pet = np.zeros((len(data),image_width,image_length),dtype=float)\n",
    "for i in range(len(data)):\n",
    "    train_other[i,:,:,:] =(imageio.imread(data[i]))\n",
    "    train_pet[i,:,:] = 0.2989 * train_other[i,:,:,0] + 0.5870 *  train_other[i,:,:,1]  + 0.1140 * train_other[i,:,:,2]\n",
    "    train_pet[i,:,:] =(train_pet[i,:,:] - np.min(train_pet[i,:,:])) / (np.max(train_pet[i,:,:]) - np.min(train_pet[i,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand the dimension to add the channel\n",
    "train_pet = np.expand_dims(train_pet,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 1, 256, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify the shape matches the pytorch standard\n",
    "train_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([272, 1, 256, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the PET training data to pytorch tensor\n",
    "train_pet_tensor = torch.from_numpy(train_pet).float()\n",
    "train_pet_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (mri_layer1): Sequential(\n",
      "    (0): Conv2d(1, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (mri_layer2): Sequential(\n",
      "    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (mri_layer3): Sequential(\n",
      "    (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (mri_layer4): Sequential(\n",
      "    (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (pet_layer1): Sequential(\n",
      "    (0): Conv2d(1, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (pet_layer2): Sequential(\n",
      "    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (pet_layer3): Sequential(\n",
      "    (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (pet_layer4): Sequential(\n",
      "    (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (fusion_layer): Sequential(\n",
      "    (0): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#define the generator network\n",
    "class Generator(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        ##### MRI Layer 1#####\n",
    "        self.mri_layer1 = nn.Sequential(                   #input shape  (,2,256,256)\n",
    "                         nn.Conv2d(in_channels=1, out_channels=48, kernel_size=5, stride=1, padding=2),\n",
    "                         nn.LeakyReLU(0.2,inplace=True))   #output shape (,48,256,256)           \n",
    "        ##### MRI Layer 2#####\n",
    "        self.mri_layer2 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=48, out_channels=48, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.LeakyReLU(0.2,inplace=True))   #output shape (,48,256,256)      \n",
    "        ##### MRI Layer 3#####\n",
    "        self.mri_layer3 = nn.Sequential(\n",
    "                         nn.Conv2d(in_channels=144, out_channels=48, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.LeakyReLU(0.2,inplace=True))   #output shape (,48,256,256)      \n",
    "        ##### MRI Layer 4#####\n",
    "        self.mri_layer4 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=192, out_channels=48, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.LeakyReLU(0.2,inplace=True))   #output shape (,48,256,256)      \n",
    " \n",
    "        \n",
    "        ##### PET Layer 1#####\n",
    "        self.pet_layer1 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=1, out_channels=48, kernel_size=5, stride=1, padding=2),\n",
    "                         nn.LeakyReLU(0.2,inplace=True))   #output shape (,48,256,256)           \n",
    "        ##### PET Layer 2#####\n",
    "        self.pet_layer2 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=48, out_channels=48, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.LeakyReLU(0.2,inplace=True))   #output shape (,48,256,256)           \n",
    "        ##### PET Layer 3#####\n",
    "        self.pet_layer3 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=144, out_channels=48, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.LeakyReLU(0.2,inplace=True))   #output shape (,48,256,256)           \n",
    "        ##### PET Layer 4#####\n",
    "        self.pet_layer4 = nn.Sequential(\n",
    "                         nn.Conv2d(in_channels=192, out_channels=48, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.LeakyReLU(0.2,inplace=True))   #output shape (,48,256,256)    \n",
    "        \n",
    "        #####Fusion Layer#####\n",
    "        self.fusion_layer = nn.Sequential( \n",
    "                           nn.Conv2d(in_channels=384, out_channels=1, kernel_size=1),\n",
    "                           nn.Tanh()) #output shape (,1,256,256)   \n",
    "\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        #MRI layer 1 \n",
    "        x1 = self.mri_layer1(x)\n",
    "        #PET layer 1 \n",
    "        y1 = self.pet_layer1(y)\n",
    "        #MRI layer 2\n",
    "        x2 = self.mri_layer2(x1)\n",
    "        #PET layer 2\n",
    "        y2 = self.pet_layer2(y1)\n",
    "        #concat layer 1\n",
    "        concat_mri1 = torch.cat((x1,x2,y2),1)\n",
    "        concat_pet1 = torch.cat((y1,y2,x2),1)\n",
    "        #MRI layer 3\n",
    "        x3 = self.mri_layer3(concat_mri1)\n",
    "        #PET layer 3\n",
    "        y3 = self.pet_layer3(concat_pet1)\n",
    "        #concat layer 2\n",
    "        concat_mri2 = torch.cat((x1,x2,x3,y3),1)\n",
    "        concat_pet2 = torch.cat((y1,y2,y3,x3),1)\n",
    "        #MRI layer 4\n",
    "        x4 = self.mri_layer4(concat_mri2)\n",
    "        #PET layer 4\n",
    "        y4 = self.pet_layer4(concat_pet2)\n",
    "        #concat layer 3\n",
    "        concat_mri3 = torch.cat((x1,x2,x3,x4),1)\n",
    "        concat_pet3 = torch.cat((y1,y2,y3,y4),1)\n",
    "        #fused layer\n",
    "        fused = self.fusion_layer(torch.cat((concat_mri3,concat_pet3),1))\n",
    "        return fused\n",
    "\n",
    "gen = Generator().to(device)\n",
    "gen = gen.float()\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (disc_layer1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (disc_layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (disc_layer3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (disc_layer4): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#define the discriminator network\n",
    "class Discriminator(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        #####Layer 1#####\n",
    "        self.disc_layer1 = nn.Sequential( #input shape (,1,256,256)\n",
    "                         nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=2, padding=1),\n",
    "                         nn.LeakyReLU(0.2,inplace=True))   #output shape (,16,256,256)           \n",
    "        #####Layer 2#####\n",
    "        self.disc_layer2 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1),\n",
    "                         nn.LeakyReLU(0.2,inplace=True))   #output shape (,32,256,256)           \n",
    "        #####Layer 3#####\n",
    "        self.disc_layer3 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1),\n",
    "                         nn.LeakyReLU(0.2,inplace=True))   #output shape (,64,256,256)  \n",
    "        #####Layer 3#####\n",
    "        self.disc_layer4 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1),\n",
    "                         nn.LeakyReLU(0.2,inplace=True))   #output shape (,128,256,256)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        #layer 1\n",
    "        x1 = self.disc_layer1(x)\n",
    "        #layer 2\n",
    "        x2 = self.disc_layer2(x1)\n",
    "        #layer 3\n",
    "        x3 = self.disc_layer3(x2)\n",
    "        #flatten the output\n",
    "        x4 = torch.flatten(x3, start_dim=1)\n",
    "        #linear and tanh layer\n",
    "        lin = torch.nn.Linear(65536,1).to(device)  \n",
    "        x5 = lin(x4)\n",
    "        score = torch.tanh(x5)\n",
    "        #print(score.shape)\n",
    "        return score\n",
    "\n",
    "disc = Discriminator().to(device)\n",
    "disc = disc.float()\n",
    "print(disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the optimizers and loss functions \n",
    "gen_optimizer = torch.optim.Adam(gen.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
    "disc_optimizer = torch.optim.Adam(disc.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
    "l2_loss   = nn.MSELoss() #MSEloss\n",
    "BCELoss   = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\nn\\functional.py:2016: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0],step: [100], mri_ssim_loss: [1.01775086], pet_ssim_loss: [1.05310309], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 0],step: [200], mri_ssim_loss: [1.06342530], pet_ssim_loss: [1.12871647], gen_loss: [5.01546812], disc_loss: [nan]\n",
      "Epoch: [ 1],step: [300], mri_ssim_loss: [1.02844763], pet_ssim_loss: [1.16632926], gen_loss: [3.59168410], disc_loss: [nan]\n",
      "Epoch: [ 1],step: [400], mri_ssim_loss: [1.01021349], pet_ssim_loss: [1.05968320], gen_loss: [2.31724620], disc_loss: [nan]\n",
      "Epoch: [ 1],step: [500], mri_ssim_loss: [1.02326405], pet_ssim_loss: [1.12253797], gen_loss: [2.47363758], disc_loss: [nan]\n",
      "Epoch: [ 2],step: [600], mri_ssim_loss: [0.96024406], pet_ssim_loss: [0.87351501], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 2],step: [700], mri_ssim_loss: [0.96507174], pet_ssim_loss: [0.87691408], gen_loss: [1.99557829], disc_loss: [nan]\n",
      "Epoch: [ 2],step: [800], mri_ssim_loss: [0.94592428], pet_ssim_loss: [0.87771606], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 3],step: [900], mri_ssim_loss: [1.01131248], pet_ssim_loss: [1.06946480], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 3],step: [1000], mri_ssim_loss: [0.90653932], pet_ssim_loss: [0.89112687], gen_loss: [1.85857463], disc_loss: [nan]\n",
      "Epoch: [ 4],step: [1100], mri_ssim_loss: [0.96117401], pet_ssim_loss: [0.90639842], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 4],step: [1200], mri_ssim_loss: [0.97490680], pet_ssim_loss: [0.94268352], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 4],step: [1300], mri_ssim_loss: [0.95351714], pet_ssim_loss: [0.93067497], gen_loss: [2.13415027], disc_loss: [1.74079287]\n",
      "Epoch: [ 5],step: [1400], mri_ssim_loss: [0.96173263], pet_ssim_loss: [0.86990541], gen_loss: [2.88494396], disc_loss: [0.75253582]\n",
      "Epoch: [ 5],step: [1500], mri_ssim_loss: [1.00005651], pet_ssim_loss: [1.01278901], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 5],step: [1600], mri_ssim_loss: [1.08556449], pet_ssim_loss: [1.09290314], gen_loss: [3.50009155], disc_loss: [nan]\n",
      "Epoch: [ 6],step: [1700], mri_ssim_loss: [1.07036579], pet_ssim_loss: [1.12966454], gen_loss: [3.68292546], disc_loss: [0.26038313]\n",
      "Epoch: [ 6],step: [1800], mri_ssim_loss: [1.04321301], pet_ssim_loss: [1.09929359], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 6],step: [1900], mri_ssim_loss: [1.04163837], pet_ssim_loss: [1.08319688], gen_loss: [4.73388577], disc_loss: [nan]\n",
      "Epoch: [ 7],step: [2000], mri_ssim_loss: [1.01907074], pet_ssim_loss: [1.05678332], gen_loss: [5.04338264], disc_loss: [0.08812749]\n",
      "Epoch: [ 7],step: [2100], mri_ssim_loss: [1.05742192], pet_ssim_loss: [1.12280154], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 8],step: [2200], mri_ssim_loss: [1.06473839], pet_ssim_loss: [1.16156173], gen_loss: [4.24966526], disc_loss: [nan]\n",
      "Epoch: [ 8],step: [2300], mri_ssim_loss: [1.01643097], pet_ssim_loss: [1.06326938], gen_loss: [2.27731419], disc_loss: [2.24302673]\n",
      "Epoch: [ 8],step: [2400], mri_ssim_loss: [1.08786345], pet_ssim_loss: [1.13994658], gen_loss: [2.42593813], disc_loss: [1.80777299]\n",
      "Epoch: [ 9],step: [2500], mri_ssim_loss: [1.02055991], pet_ssim_loss: [1.17167628], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 9],step: [2600], mri_ssim_loss: [1.02928507], pet_ssim_loss: [1.05738688], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 9],step: [2700], mri_ssim_loss: [1.07661772], pet_ssim_loss: [1.12878394], gen_loss: [4.64613819], disc_loss: [0.12803753]\n",
      "Epoch: [10],step: [2800], mri_ssim_loss: [1.01113975], pet_ssim_loss: [1.06325567], gen_loss: [2.79928446], disc_loss: [1.08611393]\n",
      "Epoch: [10],step: [2900], mri_ssim_loss: [1.06854010], pet_ssim_loss: [1.09536195], gen_loss: [4.37690020], disc_loss: [nan]\n",
      "Epoch: [11],step: [3000], mri_ssim_loss: [1.06508219], pet_ssim_loss: [1.12593389], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [11],step: [3100], mri_ssim_loss: [1.02133012], pet_ssim_loss: [1.05959368], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [11],step: [3200], mri_ssim_loss: [1.07369554], pet_ssim_loss: [1.11944437], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [12],step: [3300], mri_ssim_loss: [1.03773046], pet_ssim_loss: [1.18461514], gen_loss: [4.49604797], disc_loss: [0.15014112]\n",
      "Epoch: [12],step: [3400], mri_ssim_loss: [1.00518095], pet_ssim_loss: [1.04254270], gen_loss: [3.65043211], disc_loss: [nan]\n",
      "Epoch: [12],step: [3500], mri_ssim_loss: [1.07754636], pet_ssim_loss: [1.10544479], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [13],step: [3600], mri_ssim_loss: [1.05255175], pet_ssim_loss: [1.14724302], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [13],step: [3700], mri_ssim_loss: [1.04620874], pet_ssim_loss: [1.12406516], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [13],step: [3800], mri_ssim_loss: [1.07717502], pet_ssim_loss: [1.10068524], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [14],step: [3900], mri_ssim_loss: [1.01724827], pet_ssim_loss: [1.06271374], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [14],step: [4000], mri_ssim_loss: [1.06158543], pet_ssim_loss: [1.11032891], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [15],step: [4100], mri_ssim_loss: [1.05710542], pet_ssim_loss: [1.16472101], gen_loss: [5.46637487], disc_loss: [nan]\n",
      "Epoch: [15],step: [4200], mri_ssim_loss: [1.02331996], pet_ssim_loss: [1.06075966], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [15],step: [4300], mri_ssim_loss: [1.08651662], pet_ssim_loss: [1.16032505], gen_loss: [3.64754725], disc_loss: [nan]\n",
      "Epoch: [16],step: [4400], mri_ssim_loss: [1.02721155], pet_ssim_loss: [1.16580272], gen_loss: [6.02950382], disc_loss: [0.20166177]\n",
      "Epoch: [16],step: [4500], mri_ssim_loss: [1.07824922], pet_ssim_loss: [1.12773108], gen_loss: [7.33448315], disc_loss: [nan]\n",
      "Epoch: [16],step: [4600], mri_ssim_loss: [1.07650626], pet_ssim_loss: [1.12852013], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [17],step: [4700], mri_ssim_loss: [1.04260600], pet_ssim_loss: [1.11428154], gen_loss: [4.47383976], disc_loss: [nan]\n",
      "Epoch: [17],step: [4800], mri_ssim_loss: [1.03552198], pet_ssim_loss: [1.08777010], gen_loss: [4.91483545], disc_loss: [nan]\n",
      "Epoch: [18],step: [4900], mri_ssim_loss: [1.05727732], pet_ssim_loss: [1.10790443], gen_loss: [2.17441487], disc_loss: [nan]\n",
      "Epoch: [18],step: [5000], mri_ssim_loss: [1.01909697], pet_ssim_loss: [1.06711030], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [18],step: [5100], mri_ssim_loss: [1.07017565], pet_ssim_loss: [1.12006402], gen_loss: [3.40482521], disc_loss: [0.89235407]\n",
      "Epoch: [19],step: [5200], mri_ssim_loss: [1.03593111], pet_ssim_loss: [1.15350389], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [19],step: [5300], mri_ssim_loss: [1.00842810], pet_ssim_loss: [1.06308293], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [19],step: [5400], mri_ssim_loss: [1.07037854], pet_ssim_loss: [1.08631909], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [20],step: [5500], mri_ssim_loss: [1.04771292], pet_ssim_loss: [1.14389014], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [20],step: [5600], mri_ssim_loss: [1.03975832], pet_ssim_loss: [1.12636173], gen_loss: [2.76543999], disc_loss: [nan]\n",
      "Epoch: [20],step: [5700], mri_ssim_loss: [1.01477873], pet_ssim_loss: [1.03972650], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [21],step: [5800], mri_ssim_loss: [1.01496327], pet_ssim_loss: [1.06114352], gen_loss: [3.17900777], disc_loss: [nan]\n",
      "Epoch: [21],step: [5900], mri_ssim_loss: [1.09584510], pet_ssim_loss: [1.11285186], gen_loss: [3.38990664], disc_loss: [0.36659142]\n",
      "Epoch: [22],step: [6000], mri_ssim_loss: [1.04511249], pet_ssim_loss: [1.17931628], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [22],step: [6100], mri_ssim_loss: [1.02593732], pet_ssim_loss: [1.05661333], gen_loss: [2.97579455], disc_loss: [2.59120703]\n",
      "Epoch: [22],step: [6200], mri_ssim_loss: [1.07165360], pet_ssim_loss: [1.10899210], gen_loss: [3.60110903], disc_loss: [nan]\n",
      "Epoch: [23],step: [6300], mri_ssim_loss: [1.03783095], pet_ssim_loss: [1.15589213], gen_loss: [3.56264901], disc_loss: [0.29353964]\n",
      "Epoch: [23],step: [6400], mri_ssim_loss: [1.08317375], pet_ssim_loss: [1.14479291], gen_loss: [3.47539854], disc_loss: [0.33861274]\n",
      "Epoch: [23],step: [6500], mri_ssim_loss: [1.03865337], pet_ssim_loss: [1.07364738], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [24],step: [6600], mri_ssim_loss: [1.06482494], pet_ssim_loss: [1.12763309], gen_loss: [4.06512833], disc_loss: [0.16689630]\n",
      "Epoch: [24],step: [6700], mri_ssim_loss: [1.05022705], pet_ssim_loss: [1.08553433], gen_loss: [nan], disc_loss: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [24],step: [6800], mri_ssim_loss: [1.05815077], pet_ssim_loss: [1.05859411], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [25],step: [6900], mri_ssim_loss: [1.02035570], pet_ssim_loss: [1.05558932], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [25],step: [7000], mri_ssim_loss: [1.06957984], pet_ssim_loss: [1.13367939], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [26],step: [7100], mri_ssim_loss: [1.02903664], pet_ssim_loss: [1.17214966], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [26],step: [7200], mri_ssim_loss: [1.01244068], pet_ssim_loss: [1.06335247], gen_loss: [5.31542778], disc_loss: [nan]\n",
      "Epoch: [26],step: [7300], mri_ssim_loss: [1.11074424], pet_ssim_loss: [1.13008738], gen_loss: [3.37620878], disc_loss: [0.39653569]\n",
      "Epoch: [27],step: [7400], mri_ssim_loss: [1.04957116], pet_ssim_loss: [1.13190353], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [27],step: [7500], mri_ssim_loss: [1.04087055], pet_ssim_loss: [1.12256408], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [27],step: [7600], mri_ssim_loss: [1.05559731], pet_ssim_loss: [1.12277222], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [28],step: [7700], mri_ssim_loss: [1.01265633], pet_ssim_loss: [1.07400560], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [28],step: [7800], mri_ssim_loss: [1.08866453], pet_ssim_loss: [1.10821176], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [29],step: [7900], mri_ssim_loss: [1.03924263], pet_ssim_loss: [1.09430313], gen_loss: [3.85699034], disc_loss: [nan]\n",
      "Epoch: [29],step: [8000], mri_ssim_loss: [1.02198100], pet_ssim_loss: [1.05828023], gen_loss: [6.89378357], disc_loss: [nan]\n",
      "Epoch: [29],step: [8100], mri_ssim_loss: [1.04655886], pet_ssim_loss: [1.07039547], gen_loss: [4.34012747], disc_loss: [0.11459598]\n",
      "Epoch: [30],step: [8200], mri_ssim_loss: [1.04023993], pet_ssim_loss: [1.16679192], gen_loss: [3.14278984], disc_loss: [0.49807337]\n",
      "Epoch: [30],step: [8300], mri_ssim_loss: [1.00353229], pet_ssim_loss: [1.02192843], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [30],step: [8400], mri_ssim_loss: [1.08556449], pet_ssim_loss: [1.09290314], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [31],step: [8500], mri_ssim_loss: [1.07036579], pet_ssim_loss: [1.12966454], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [31],step: [8600], mri_ssim_loss: [1.04321301], pet_ssim_loss: [1.09929359], gen_loss: [6.16258335], disc_loss: [0.01811469]\n",
      "Epoch: [31],step: [8700], mri_ssim_loss: [1.04163837], pet_ssim_loss: [1.08319688], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [32],step: [8800], mri_ssim_loss: [1.01907074], pet_ssim_loss: [1.05678332], gen_loss: [3.68212318], disc_loss: [nan]\n",
      "Epoch: [32],step: [8900], mri_ssim_loss: [1.05742192], pet_ssim_loss: [1.12280154], gen_loss: [2.50349641], disc_loss: [nan]\n",
      "Epoch: [33],step: [9000], mri_ssim_loss: [1.06473839], pet_ssim_loss: [1.16156173], gen_loss: [4.00080299], disc_loss: [nan]\n",
      "Epoch: [33],step: [9100], mri_ssim_loss: [1.01643097], pet_ssim_loss: [1.06326938], gen_loss: [4.95108128], disc_loss: [0.05828687]\n",
      "Epoch: [33],step: [9200], mri_ssim_loss: [1.08786345], pet_ssim_loss: [1.13994658], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [34],step: [9300], mri_ssim_loss: [1.02055991], pet_ssim_loss: [1.17167628], gen_loss: [3.91739464], disc_loss: [0.19619107]\n",
      "Epoch: [34],step: [9400], mri_ssim_loss: [1.02928507], pet_ssim_loss: [1.05738688], gen_loss: [3.80704808], disc_loss: [nan]\n",
      "Epoch: [34],step: [9500], mri_ssim_loss: [1.07661772], pet_ssim_loss: [1.12878394], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [35],step: [9600], mri_ssim_loss: [1.01113975], pet_ssim_loss: [1.06325567], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [35],step: [9700], mri_ssim_loss: [1.06854010], pet_ssim_loss: [1.09536195], gen_loss: [3.50381374], disc_loss: [nan]\n",
      "Epoch: [36],step: [9800], mri_ssim_loss: [1.06508219], pet_ssim_loss: [1.12593389], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [36],step: [9900], mri_ssim_loss: [1.02133012], pet_ssim_loss: [1.05959368], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [36],step: [10000], mri_ssim_loss: [1.07369554], pet_ssim_loss: [1.11944437], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [37],step: [10100], mri_ssim_loss: [1.03773046], pet_ssim_loss: [1.18461514], gen_loss: [4.73661423], disc_loss: [nan]\n",
      "Epoch: [37],step: [10200], mri_ssim_loss: [1.00518095], pet_ssim_loss: [1.04254270], gen_loss: [3.80013657], disc_loss: [nan]\n",
      "Epoch: [37],step: [10300], mri_ssim_loss: [1.07754636], pet_ssim_loss: [1.10544479], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [38],step: [10400], mri_ssim_loss: [1.05255175], pet_ssim_loss: [1.14724302], gen_loss: [2.72080326], disc_loss: [nan]\n",
      "Epoch: [38],step: [10500], mri_ssim_loss: [1.04620874], pet_ssim_loss: [1.12406516], gen_loss: [4.25555134], disc_loss: [nan]\n",
      "Epoch: [38],step: [10600], mri_ssim_loss: [1.07717502], pet_ssim_loss: [1.10068524], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [39],step: [10700], mri_ssim_loss: [1.01724827], pet_ssim_loss: [1.06271374], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [39],step: [10800], mri_ssim_loss: [1.06158543], pet_ssim_loss: [1.11032891], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [40],step: [10900], mri_ssim_loss: [1.05710542], pet_ssim_loss: [1.16472101], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [40],step: [11000], mri_ssim_loss: [1.02331996], pet_ssim_loss: [1.06075966], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [40],step: [11100], mri_ssim_loss: [1.08651662], pet_ssim_loss: [1.16032505], gen_loss: [2.88485408], disc_loss: [0.75150013]\n",
      "Epoch: [41],step: [11200], mri_ssim_loss: [1.02721155], pet_ssim_loss: [1.16580272], gen_loss: [3.10348701], disc_loss: [nan]\n",
      "Epoch: [41],step: [11300], mri_ssim_loss: [1.07824922], pet_ssim_loss: [1.12773108], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [41],step: [11400], mri_ssim_loss: [1.07650626], pet_ssim_loss: [1.12852013], gen_loss: [3.12947226], disc_loss: [0.50542551]\n",
      "Epoch: [42],step: [11500], mri_ssim_loss: [1.04260600], pet_ssim_loss: [1.11428154], gen_loss: [2.74144173], disc_loss: [2.04269695]\n",
      "Epoch: [42],step: [11600], mri_ssim_loss: [1.03552198], pet_ssim_loss: [1.08777010], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [43],step: [11700], mri_ssim_loss: [1.05727732], pet_ssim_loss: [1.10790443], gen_loss: [3.16872311], disc_loss: [nan]\n",
      "Epoch: [43],step: [11800], mri_ssim_loss: [1.01909697], pet_ssim_loss: [1.06711030], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [43],step: [11900], mri_ssim_loss: [1.07017565], pet_ssim_loss: [1.12006402], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [44],step: [12000], mri_ssim_loss: [1.03593111], pet_ssim_loss: [1.15350389], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [44],step: [12100], mri_ssim_loss: [1.00842810], pet_ssim_loss: [1.06308293], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [44],step: [12200], mri_ssim_loss: [1.07037854], pet_ssim_loss: [1.08631909], gen_loss: [2.30862308], disc_loss: [1.95936728]\n",
      "Epoch: [45],step: [12300], mri_ssim_loss: [1.04771292], pet_ssim_loss: [1.14389014], gen_loss: [3.48059082], disc_loss: [0.32234198]\n",
      "Epoch: [45],step: [12400], mri_ssim_loss: [1.03975832], pet_ssim_loss: [1.12636173], gen_loss: [3.43489861], disc_loss: [nan]\n",
      "Epoch: [45],step: [12500], mri_ssim_loss: [1.01477873], pet_ssim_loss: [1.03972650], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [46],step: [12600], mri_ssim_loss: [1.01496327], pet_ssim_loss: [1.06114352], gen_loss: [3.22624540], disc_loss: [0.38066459]\n",
      "Epoch: [46],step: [12700], mri_ssim_loss: [1.09584510], pet_ssim_loss: [1.11285186], gen_loss: [3.43125963], disc_loss: [nan]\n",
      "Epoch: [47],step: [12800], mri_ssim_loss: [1.04511249], pet_ssim_loss: [1.17931628], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [47],step: [12900], mri_ssim_loss: [1.02593732], pet_ssim_loss: [1.05661333], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [47],step: [13000], mri_ssim_loss: [1.07165360], pet_ssim_loss: [1.10899210], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [48],step: [13100], mri_ssim_loss: [1.03783095], pet_ssim_loss: [1.15589213], gen_loss: [3.75590754], disc_loss: [nan]\n",
      "Epoch: [48],step: [13200], mri_ssim_loss: [1.08317375], pet_ssim_loss: [1.14479291], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [48],step: [13300], mri_ssim_loss: [1.03865337], pet_ssim_loss: [1.07364738], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [49],step: [13400], mri_ssim_loss: [1.06482494], pet_ssim_loss: [1.12763309], gen_loss: [3.74462819], disc_loss: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [49],step: [13500], mri_ssim_loss: [1.05022705], pet_ssim_loss: [1.08553433], gen_loss: [2.15574646], disc_loss: [nan]\n",
      "Epoch: [49],step: [13600], mri_ssim_loss: [1.05815077], pet_ssim_loss: [1.05859411], gen_loss: [3.37490129], disc_loss: [nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Generator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Discriminator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# perform the training\n",
    "counter = 0\n",
    "Tensor = torch.cuda.FloatTensor if device else torch.FloatTensor\n",
    "# Adversarial ground truths\n",
    "one = Tensor(np.ones((1)))\n",
    "zero = Tensor(np.zeros((1)))\n",
    "\n",
    "start_time = time.time()\n",
    "lamda = 1\n",
    "ep_ssim_mri_loss = []\n",
    "ep_ssim_pet_loss = []\n",
    "ep_adv_loss = []\n",
    "ep_disc_loss = []\n",
    "ep_gen_loss =[]\n",
    "for epoch in range(EPOCH):\n",
    "    ssim_mri_Loss = []\n",
    "    ssim_pet_Loss   = []\n",
    "    adv_Loss = []\n",
    "    gen_Loss = []\n",
    "    disc_Loss = []\n",
    "    #run batch images\n",
    "    batch_idxs = 272 // batch_size\n",
    "    for idx in range(0, batch_idxs):\n",
    "        #ge tthe mri and pet batches\n",
    "        b_x = train_mri_tensor[idx*batch_size : (idx+1)*batch_size,:,:,:].to(device)\n",
    "        b_y = train_pet_tensor[idx*batch_size : (idx+1)*batch_size,:,:,:].to(device)\n",
    "        counter += 1\n",
    "        \n",
    "        #clear the generator gradients\n",
    "        gen_optimizer.zero_grad()    \n",
    "\n",
    "        #get a fused image from generator\n",
    "        output = gen(b_x,b_y)               # gen output\n",
    "        \n",
    "        #feed the fused image into the discriminator 1 and 2\n",
    "        fused_disc_score = disc(output)\n",
    "        \n",
    "        #define the generator loss\n",
    "        ssim_loss_mri = 1 - ssim(output, b_x,data_range=1)\n",
    "        ssim_loss_pet = 1 - ssim(output, b_y,data_range=1)\n",
    "        ssim_loss = ssim_loss_mri + ssim_loss_pet\n",
    "        adv_loss = BCELoss(fused_disc_score, one)\n",
    "        gen_loss = ssim_loss + adv_loss\n",
    "        \n",
    "        #update the generator\n",
    "        gen_loss.backward(retain_graph=True)                 # backpropagation, compute gradients\n",
    "        gen_optimizer.step()                # apply gradients\n",
    "        \n",
    "        #clear the discriminator gradients\n",
    "        disc_optimizer.zero_grad()  \n",
    "        \n",
    "        #feed the MRI image and PET images into the discriminator 1 and 2 respectively\n",
    "        mri_disc_score = disc(b_x.detach())\n",
    "        \n",
    "        #define the discriminator loss\n",
    "        disc_real = BCELoss(mri_disc_score, one)\n",
    "        disc_fake = BCELoss(fused_disc_score, zero)\n",
    "        disc_loss = disc_real  + disc_fake\n",
    "        \n",
    "        #update the discriminator\n",
    "        disc_loss.backward()                 # backpropagation, compute gradients\n",
    "        disc_optimizer.step()                # apply gradients  \n",
    "\n",
    "        #store all the loss values at each epoch\n",
    "        ssim_mri_Loss.append(ssim_loss_mri.item())\n",
    "        ssim_pet_Loss.append(ssim_loss_pet.item())\n",
    "        gen_Loss.append(gen_loss.item())\n",
    "        disc_Loss.append(disc_loss.item())\n",
    "        if counter % 100 == 0:\n",
    "            print(\"Epoch: [%2d],step: [%2d], mri_ssim_loss: [%.8f], pet_ssim_loss: [%.8f], gen_loss: [%.8f], disc_loss: [%.8f]\" \n",
    "            %(epoch, counter, ssim_loss_mri, ssim_loss_pet, gen_loss, disc_loss))\n",
    "    \n",
    "    av_ssim_mri_loss = np.average(ssim_mri_Loss)\n",
    "    ep_ssim_mri_loss.append(av_ssim_mri_loss)\n",
    "    \n",
    "    av_ssim_pet_loss = np.average(ssim_pet_Loss)\n",
    "    ep_ssim_pet_loss.append(av_ssim_pet_loss)\n",
    "    \n",
    "    av_gen_loss = np.average(gen_Loss)\n",
    "    ep_gen_loss.append(av_gen_loss)\n",
    "    \n",
    "    av_disc_loss = np.average(disc_Loss)\n",
    "    ep_disc_loss.append(av_disc_loss)\n",
    "    \n",
    "    if(epoch == EPOCH -1):\n",
    "        #Save a checkpoint\n",
    "        torch.save(gen,  'C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/ACGAN/checkpoint_gen.pth') \n",
    "        torch.save(disc, 'C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/ACGAN/checkpoint_disc.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = np.asarray(ep_ssim_mri_loss)\n",
    "l2 = np.asarray(ep_ssim_pet_loss)\n",
    "l4 = np.asarray(ep_gen_loss)\n",
    "l5 = np.asarray(ep_disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('C:/Users/horan/Desktop/Suraka/Loss curves/DDcGAN/H5 Files/Loss_GEN.h5', 'w')\n",
    "h5f.create_dataset('MRI_dataset', data=l4)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x257176a65c0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(l1)\n",
    "#plt.savefig('C:/Users/horan/Desktop/Suraka/Loss curves/VIFNet/Loss curves/SSIM_MRI_loss_curve.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test input MRI dataset\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/MRI/')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/MRI/')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "test_mri = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    test_mri[i,:,:] =(imageio.imread(data[i]))\n",
    "    test_mri[i,:,:] =(test_mri[i,:,:] - np.min(test_mri[i,:,:])) / (np.max(test_mri[i,:,:]) - np.min(test_mri[i,:,:]))\n",
    "    test_mri[i,:,:] = np.float32(test_mri[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "test_mri = np.expand_dims(test_mri,axis=1)\n",
    "#verify the shape matches the pytorch standard\n",
    "test_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the test mri image\n",
    "#test_mri = test_mri[0,:,:,:]\n",
    "#test_mri = np.expand_dims(test_mri,axis=0)\n",
    "plt.imshow(test_mri[0,0,:,:],'gray')\n",
    "#plt.savefig('MRI.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the MRI Testing data to pytorch tensor\n",
    "test_mri_tensor = torch.from_numpy(test_mri).float()\n",
    "print(test_mri_tensor.shape)\n",
    "test_mri_tensor.requires_grad =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test input PET dataset\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/PET/')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/PET/')\n",
    "data = glob.glob(os.path.join(dataset, \"*.png\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "test_pet = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    test_pet[i,:,:] =(imageio.imread(data[i]))\n",
    "    test_pet[i,:,:] =(test_pet[i,:,:] - np.min(test_pet[i,:,:])) / (np.max(test_pet[i,:,:]) - np.min(test_pet[i,:,:]))\n",
    "    test_pet[i,:,:] = np.float32(test_pet[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "test_pet = np.expand_dims(test_pet,axis=1)\n",
    "#verify the shape matches the pytorch standard\n",
    "test_pet.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the test pet image\n",
    "#test_pet = test_pet[2,:,:,:]\n",
    "#test_pet = np.expand_dims(test_pet,axis=0)\n",
    "plt.imshow(test_pet[0,0,:,:],'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_pet[0,0,:,:],'gray')\n",
    "#plt.savefig('PET.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the MRI Testing data to pytorch tensor\n",
    "test_pet_tensor = torch.from_numpy(test_pet).float()\n",
    "print(test_pet_tensor.shape)\n",
    "test_pet_tensor.requires_grad =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gen =torch.load('C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/FuseGAN/checkpoint_gen.pth')\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted the fused image\n",
    "fused = gen(test_mri_tensor.to(device), test_pet_tensor.to(device))\n",
    "fused_numpy = fused.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the output image\n",
    "plt.imshow(fused_numpy[0,0,:,:],'gray')\n",
    "#plt.savefig('Fused.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imageio.imwrite('C:/Users/horan/Desktop/Suraka/Fused/Fused.png',np.uint8(cv2.normalize(fused_numpy[0,0,:,:], None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the guidance image for MRI and PET wrt to the fused image\n",
    "time1 = time.time()\n",
    "count = 0 \n",
    "guide_fuse_mri = np.zeros((256,256),dtype=float)\n",
    "guide_fuse_pet = np.zeros((256,256),dtype=float)\n",
    "\n",
    "for y_coord in range(0,256):\n",
    "    for x_coord in range(0,256):\n",
    "        jacob_fuse_mri = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_mri_tensor, retain_graph=True, create_graph=True)[0]\n",
    "        jacob_numpy_mri = np.squeeze(jacob_fuse_mri.data.cpu().numpy())  \n",
    "        guide_fuse_mri[y_coord,x_coord] = jacob_numpy_mri[y_coord,x_coord]\n",
    "        jacob_fuse_pet = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_pet_tensor, retain_graph=True, create_graph=True)[0]\n",
    "        jacob_numpy_pet = np.squeeze(jacob_fuse_pet.data.cpu().numpy())  \n",
    "        guide_fuse_pet[y_coord,x_coord] = jacob_numpy_pet[y_coord,x_coord]\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print('Count is %d' %count)\n",
    "time2 = time.time()\n",
    "print('Time taken to compute is %d seconds' %(time2-time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "plt.colorbar()\n",
    "#plt.savefig('Jacob_Fused_MRI.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guide_fuse_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "#plt.colorbar()\n",
    "#plt.savefig('Jacob_Fused_PET.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guide_fuse_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(fused_RGB)\n",
    "#plt.savefig('Fused_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(mri_RGB)\n",
    "#plt.savefig('MRI_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(pet_RGB)\n",
    "#plt.savefig('PET_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5f = h5py.File('C:/Users/horan/Desktop/Suraka/Jacobian_MRI.h5', 'w')\n",
    "#h5f.create_dataset('MRI_dataset', data=guide_fuse_mri)\n",
    "#h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5f = h5py.File('C:/Users/horan/Desktop/Suraka/Jacobian_PET.h5', 'w')\n",
    "#h5f.create_dataset('PET_dataset', data=guide_fuse_pet)\n",
    "#h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/H5 Files/Jacobian_MRI.h5', 'r')\n",
    "guide_fuse_mri =  np.array(hf.get('MRI_dataset'))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/H5 Files/Jacobian_PET.h5', 'r')\n",
    "guide_fuse_pet =  np.array(hf.get('PET_dataset'))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define overlay images\n",
    "fused_RGB = np.zeros((256,256,3),dtype=float)\n",
    "mri_RGB   = np.zeros((256,256,3),dtype=float)\n",
    "pet_RGB   = np.zeros((256,256,3),dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_RGB[:,:,0]  = guide_fuse_mri \n",
    "fused_RGB[:,:,1]  = guide_fuse_pet \n",
    "fused_RGB[:,:,2]  = fused_numpy[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fused_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_RGB[:,:,0]  = guide_fuse_mri\n",
    "mri_RGB[:,:,1]  = guide_fuse_pet \n",
    "mri_RGB[:,:,2]  = test_mri[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mri_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_RGB[:,:,0]  = guide_fuse_mri\n",
    "pet_RGB[:,:,1]  = guide_fuse_pet \n",
    "pet_RGB[:,:,2]  = test_pet[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pet_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the window\n",
    "root = Tk()  \n",
    "root.title('Visualisation of fusion networks')\n",
    "root.configure(background='white')\n",
    "\n",
    "\n",
    "#Label the images\n",
    "#fontStyle = tkFont.Font(family=\"Lucida Grande\", size=15)\n",
    "#w1 = tk.Label(root, bg='white', font=fontStyle, text=\"Fused Image\")\n",
    "#w1.grid(row=0, column=1)\n",
    "#w1.pack()\n",
    "\n",
    "#define the frame\n",
    "canvasframe = Frame(root)  # define Input and output frame\n",
    "buttonframe = Frame(root)  # define button frame\n",
    "canvasframe.pack()  # pack the Input and Output frame\n",
    "buttonframe.pack()  # pack the button frame\n",
    "\n",
    "\n",
    "#define the canvas\n",
    "canvas = Canvas(canvasframe, width=1800, height=920, bg = 'white')\n",
    "canvas.grid(row=0, column=0)\n",
    "\n",
    "#Insert fused image to the canvas\n",
    "img_fused = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/Fused/Fused.png\") # load the image\n",
    "canvas.create_image(0, 0, image=img_fused, anchor=NW)\n",
    "\n",
    "#Insert MRI image to the canvas\n",
    "img_mri = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/MRI/MRI.gif\") # load the image\n",
    "canvas.create_image(620, 0, image=img_mri, anchor=NW)\n",
    "\n",
    "#Insert PET image to the canvas\n",
    "img_pet = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/PET/3.png\") # load the image\n",
    "canvas.create_image(1240, 0, image=img_pet, anchor=NW)\n",
    "\n",
    "def start_mouseover():  # function called when user clicks the button \n",
    "    # link the function to the left-mouse-click event\n",
    "    canvas.bind(\"<B1-Motion>\", Coordinates)\n",
    "\n",
    "def Coordinates(event): # function called when left-mouse-button is clicked with a mouseover\n",
    "    x_coord = event.x  # save x and y coordinates selected by the user   \n",
    "    y_coord = event.y\n",
    "    print('mouse position is at' + '(' + str(y_coord) + ',' + str(x_coord) + ')', end='\\r')\n",
    "    #display the output MRI Jacobian image\n",
    "    #img_MR_out = ImageTk.PhotoImage(file ='C:/Users/cgvadmin/Desktop/Suraka/Fused_MRI/im_' + str(y_coord) + '_' + str(x_coord) + '.png') # load the image\n",
    "    jacobian_fuse_mri = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_mri_tensor, retain_graph=True, create_graph=True)[0]\n",
    "    jacobian_fuse_pet = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_pet_tensor, retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    jacob_val_mri = np.squeeze(jacobian_fuse_mri.data.cpu().numpy())    \n",
    "    jacob_val_pet = np.squeeze(jacobian_fuse_pet.data.cpu().numpy())\n",
    "    \n",
    "    x_mri = np.asarray(np.where(np.any(jacob_val_mri, axis = 0)))\n",
    "    y_mri = np.asarray(np.where(np.any(jacob_val_mri, axis = 1)))\n",
    "    minx_mri, maxx_mri, miny_mri, maxy_mri = np.min(x_mri), np.max(x_mri), np.min(y_mri), np.max(y_mri)  #return min and max coordinates\n",
    "    zoom_im_mri = jacob_val_mri[miny_mri:maxy_mri,minx_mri:maxx_mri] \n",
    "    \n",
    "    x_pet = np.asarray(np.where(np.any(jacob_val_pet, axis = 0)))\n",
    "    y_pet = np.asarray(np.where(np.any(jacob_val_pet, axis = 1)))\n",
    "    minx_pet, maxx_pet, miny_pet, maxy_pet = np.min(x_pet), np.max(x_pet), np.min(y_pet), np.max(y_pet)  #return min and max coordinates\n",
    "    zoom_im_pet = jacob_val_pet[miny_pet:maxy_pet,minx_pet:maxx_pet] \n",
    "    \n",
    "    plt.imshow(fused_numpy[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom Fused')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo11.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out11 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo11.png')\n",
    "    canvas.create_image(320,0,image=im_out11,anchor=NW)\n",
    "    canvas.image11 = im_out11\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(test_mri[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom MRI')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo12.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out12 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo12.png')\n",
    "    canvas.create_image(950,0,image=im_out12,anchor=NW)\n",
    "    canvas.image12 = im_out12\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(test_pet[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom PET')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo13.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out13 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo13.png')\n",
    "    canvas.create_image(1500,0,image=im_out13,anchor=NW)\n",
    "    canvas.image13 = im_out13\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(jacob_val_mri,cmap='viridis', aspect ='equal')\n",
    "    plt.title('Fused wrt MRI')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo1.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out1 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo1.png')\n",
    "    canvas.create_image(0,320,image=im_out1,anchor=NW)\n",
    "    canvas.image1 = im_out1\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    #f.add_subplot(1,5,2)\n",
    "    plt.imshow(zoom_im_mri,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Zoomed (Fused wrt MRI)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo2.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out2 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo2.png')\n",
    "    canvas.create_image(280,320,image=im_out2,anchor=NW)\n",
    "    canvas.image2 = im_out2\n",
    "    #plt.tight_layout()\n",
    "    #divider = make_axes_locatable(plt)\n",
    "    #cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    #plt.colorbar(cax=cax)\n",
    "    \n",
    "    #f.add_subplot(1,5,3)\n",
    "    plt.xlim(0,0.7)\n",
    "    plt.ylim(0,0.7)\n",
    "    plt.plot(jacob_val_mri[y_coord,x_coord],jacob_val_pet[y_coord,x_coord],'-ro')\n",
    "    plt.xlabel('MRI pixel score (Fused wrt MRI)')\n",
    "    plt.ylabel('PET pixel score (Fused wrt PET)')\n",
    "    plt.title('Mouse position at: (' + str(y_coord) + ',' + str(x_coord) + ')')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.draw()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo3.png', bbox_inches = 'tight',pad_inches = 0.1)\n",
    "    plt.close()\n",
    "    im_out3 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo3.png')\n",
    "    canvas.create_image(600,320,image=im_out3,anchor=NW)\n",
    "    canvas.image3 = im_out3\n",
    "    \n",
    "    #f.add_subplot(1,5,4)\n",
    "    plt.imshow(jacob_val_pet,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Fused wrt PET')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo4.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out4 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo4.png')\n",
    "    canvas.create_image(900,320,image=im_out4,anchor=NW)\n",
    "    canvas.image4 = im_out4\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    #f.add_subplot(1,5,5)\n",
    "    plt.imshow(zoom_im_pet,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Zoomed (Fused wrt PET)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo5.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out5 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo5.png')\n",
    "    canvas.create_image(1180,320,image=im_out5,anchor=NW)\n",
    "    canvas.image5 = im_out5\n",
    "\n",
    "    plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "    plt.title('Fused wrt MRI')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo6.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out6 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo6.png')\n",
    "    canvas.create_image(0,650,image=im_out6,anchor=NW)\n",
    "    canvas.image6 = im_out6\n",
    "    \n",
    "    plt.imshow(fused_RGB)\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo8.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out8 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo8.png')\n",
    "    canvas.create_image(300,650,image=im_out8,anchor=NW)\n",
    "    canvas.image8 = im_out8\n",
    "    \n",
    "    plt.imshow(mri_RGB)\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo9.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out9 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo9.png')\n",
    "    canvas.create_image(600,650,image=im_out9,anchor=NW)\n",
    "    canvas.image9 = im_out9\n",
    "    \n",
    "    plt.imshow(pet_RGB)\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo10.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out10 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo10.png')\n",
    "    canvas.create_image(900,650,image=im_out10,anchor=NW)\n",
    "    canvas.image10 = im_out10\n",
    "    \n",
    "    plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo7.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out7 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo7.png')\n",
    "    canvas.create_image(1200,650,image=im_out7,anchor=NW)\n",
    "    canvas.image7 = im_out7\n",
    "    \n",
    "    radius = 5\n",
    "    i = canvas.create_oval(x_coord-radius, y_coord-radius, x_coord+radius, y_coord+radius, fill = 'red')\n",
    "    canvas.after(20,canvas.delete,i)\n",
    "\n",
    "# insert button to the middleframe and link it to \"Start Mouseover\"\n",
    "button_start_mouseover = Button(buttonframe, text=\"Start Mouseover\",command=start_mouseover)\n",
    "button_start_mouseover.grid(row=1, column=0, pady=0)\n",
    "\n",
    "\n",
    "root.mainloop()  #keep the GUI open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
