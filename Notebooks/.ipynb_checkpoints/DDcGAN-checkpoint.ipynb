{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models.vgg import vgg19\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from skimage import img_as_ubyte\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision      # dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "import argparse\n",
    "import glob\n",
    "import imageio\n",
    "from skimage import color\n",
    "import numpy\n",
    "import natsort\n",
    "import scipy\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "import pprint\n",
    "from scipy.ndimage import correlate\n",
    "from scipy.ndimage.filters import gaussian_gradient_magnitude\n",
    "import torchvision.datasets as dset\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import os.path\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import tkinter.font as tkFont\n",
    "from PIL import ImageTk, Image\n",
    "import pylab\n",
    "import cv2\n",
    "import h5py\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11811160064\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(torch.cuda.get_device_properties(0).total_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the hyperparameters\n",
    "image_length = 256\n",
    "image_width  = 256\n",
    "mr_channels  = 1\n",
    "gray_channels = 1\n",
    "pet_channels = 4    \n",
    "rgb_channels = 3     \n",
    "batch_size   = 1\n",
    "EPOCH = 50\n",
    "learning_rate = 0.002 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the train mri data\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/Training/MRI')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/Training/MRI')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "train_mri = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    train_mri[i,:,:] =(imageio.imread(data[i]))\n",
    "    train_mri[i,:,:] =(train_mri[i,:,:] - np.min(train_mri[i,:,:])) / (np.max(train_mri[i,:,:]) - np.min(train_mri[i,:,:]))\n",
    "    train_mri[i,:,:] = np.float32(train_mri[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "train_mri = np.expand_dims(train_mri,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 1, 256, 256)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify the shape matches the pytorch standard\n",
    "train_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([272, 1, 256, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the MRI training data to pytorch tensor\n",
    "train_mri_tensor = torch.from_numpy(train_mri).float()\n",
    "train_mri_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the train pet data\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/Training/PET')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/Training/PET')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "train_other = np.zeros((len(data),image_width,image_length,pet_channels),dtype=float)\n",
    "train_pet = np.zeros((len(data),image_width,image_length),dtype=float)\n",
    "for i in range(len(data)):\n",
    "    train_other[i,:,:,:] =(imageio.imread(data[i]))\n",
    "    train_pet[i,:,:] = 0.2989 * train_other[i,:,:,0] + 0.5870 *  train_other[i,:,:,1]  + 0.1140 * train_other[i,:,:,2]\n",
    "    train_pet[i,:,:] =(train_pet[i,:,:] - np.min(train_pet[i,:,:])) / (np.max(train_pet[i,:,:]) - np.min(train_pet[i,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand the dimension to add the channel\n",
    "train_pet = np.expand_dims(train_pet,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 1, 256, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify the shape matches the pytorch standard\n",
    "train_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([272, 1, 256, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the PET training data to pytorch tensor\n",
    "train_pet_tensor = torch.from_numpy(train_pet).float()\n",
    "train_pet_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (gen_layer1): Sequential(\n",
      "    (0): Conv2d(2, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (gen_layer2): Sequential(\n",
      "    (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (gen_layer3): Sequential(\n",
      "    (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (gen_layer4): Sequential(\n",
      "    (0): Conv2d(144, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (gen_layer5): Sequential(\n",
      "    (0): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (gen_layer6): Sequential(\n",
      "    (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (gen_layer7): Sequential(\n",
      "    (0): Conv2d(240, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (gen_layer8): Sequential(\n",
      "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (gen_layer9): Sequential(\n",
      "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (gen_layer10): Sequential(\n",
      "    (0): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#define the generator network\n",
    "class Generator(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        ##### Encoder Layer 1#####\n",
    "        self.gen_layer1 = nn.Sequential( #input shape (,2,256,256)\n",
    "                         nn.Conv2d(in_channels=2, out_channels=48, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.BatchNorm2d(48),\n",
    "                         nn.ReLU())        \n",
    "        ##### Encoder Layer 2#####\n",
    "        self.gen_layer2 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=48, out_channels=48, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.BatchNorm2d(48),\n",
    "                         nn.ReLU())    \n",
    "        ##### Encoder Layer 3#####\n",
    "        self.gen_layer3 = nn.Sequential(\n",
    "                         nn.Conv2d(in_channels=96, out_channels=48, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.BatchNorm2d(48),\n",
    "                         nn.ReLU())     \n",
    "        ##### Encoder Layer 4#####\n",
    "        self.gen_layer4 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=144, out_channels=48, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.BatchNorm2d(48),\n",
    "                         nn.ReLU())      \n",
    "        ##### Encoder Layer 5#####\n",
    "        self.gen_layer5 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=192, out_channels=48, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.BatchNorm2d(48),\n",
    "                         nn.ReLU())        \n",
    "        \n",
    "        ##### Decoder Layer 1#####\n",
    "        self.gen_layer6 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=240, out_channels=240, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.BatchNorm2d(240),\n",
    "                         nn.ReLU())     \n",
    "        ##### Decoder Layer 2#####\n",
    "        self.gen_layer7 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=240, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.BatchNorm2d(128),\n",
    "                         nn.ReLU())       \n",
    "        ##### Decoder Layer 3#####\n",
    "        self.gen_layer8 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.BatchNorm2d(64),\n",
    "                         nn.ReLU())       \n",
    "        ##### Decoder Layer 4#####\n",
    "        self.gen_layer9 = nn.Sequential(\n",
    "                         nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.BatchNorm2d(32),\n",
    "                         nn.ReLU())       \n",
    "        ##### Decoder Layer 5#####\n",
    "        self.gen_layer10 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=32, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.BatchNorm2d(1),\n",
    "                         nn.Tanh())        \n",
    "\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        #Encoder \n",
    "        xy = torch.cat((x,y),1)\n",
    "        x1 = self.gen_layer1(xy)\n",
    "        x2 = self.gen_layer2(x1)\n",
    "        concat1 = torch.cat((x1,x2),1)\n",
    "        x3 = self.gen_layer3(concat1)\n",
    "        concat2 = torch.cat((x3,concat1),1)\n",
    "        x4 = self.gen_layer4(concat2)\n",
    "        concat3 = torch.cat((x4,concat2),1)\n",
    "        x5 = self.gen_layer5(concat3)\n",
    "        concat4 = torch.cat((x5,concat3),1)\n",
    "        #Decoder\n",
    "        x6 = self.gen_layer6(concat4)\n",
    "        x7 = self.gen_layer7(x6)\n",
    "        x8 = self.gen_layer8(x7)\n",
    "        x9 = self.gen_layer9(x8)\n",
    "        fused = self.gen_layer10(x9)\n",
    "        return fused\n",
    "\n",
    "gen = Generator().to(device)\n",
    "gen = gen.float()\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator1(\n",
      "  (disc_layer1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (disc_layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (disc_layer3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#define the generator network\n",
    "class Discriminator1(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super(Discriminator1, self).__init__()\n",
    "        #####Layer 1#####\n",
    "        self.disc_layer1 = nn.Sequential( #input shape (,1,256,256)\n",
    "                         nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=2, padding=1),\n",
    "                         nn.ReLU())   \n",
    "        #####Layer 2#####\n",
    "        self.disc_layer2 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1),\n",
    "                         nn.BatchNorm2d(32),\n",
    "                         nn.ReLU()) \n",
    "        #####Layer 3#####\n",
    "        self.disc_layer3 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1),\n",
    "                         nn.BatchNorm2d(64),  \n",
    "                         nn.ReLU())  \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #layer 1\n",
    "        x1 = self.disc_layer1(x)\n",
    "        #layer 2\n",
    "        x2 = self.disc_layer2(x1)\n",
    "        #layer 3\n",
    "        x3 = self.disc_layer3(x2)\n",
    "        #flatten the output\n",
    "        x4 = torch.flatten(x3, start_dim=1)\n",
    "        #linear and tanh layer\n",
    "        lin = torch.nn.Linear(65536,1).to(device)  \n",
    "        x5 = lin(x4)\n",
    "        score = torch.tanh(x5)\n",
    "        #print(score.shape)\n",
    "        return score\n",
    "\n",
    "disc1 = Discriminator1().to(device)\n",
    "disc1 = disc1.float()\n",
    "print(disc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator2(\n",
      "  (disc_layer1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (disc_layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (disc_layer3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#define the generator network\n",
    "class Discriminator2(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super(Discriminator2, self).__init__()\n",
    "        #####Layer 1#####\n",
    "        self.disc_layer1 = nn.Sequential( #input shape (,1,256,256)\n",
    "                         nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=2, padding=1),\n",
    "                         nn.ReLU())   \n",
    "        #####Layer 2#####\n",
    "        self.disc_layer2 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1),\n",
    "                         nn.BatchNorm2d(32),\n",
    "                         nn.ReLU()) \n",
    "        #####Layer 3#####\n",
    "        self.disc_layer3 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1),\n",
    "                         nn.BatchNorm2d(64),  \n",
    "                         nn.ReLU())  \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #layer 1\n",
    "        x1 = self.disc_layer1(x)\n",
    "        #layer 2\n",
    "        x2 = self.disc_layer2(x1)\n",
    "        #layer 3\n",
    "        x3 = self.disc_layer3(x2)\n",
    "        #flatten the output\n",
    "        x4 = torch.flatten(x3, start_dim=1)\n",
    "        #linear and tanh layer\n",
    "        lin = torch.nn.Linear(65536,1).to(device)  \n",
    "        x5 = lin(x4)\n",
    "        score = torch.tanh(x5)\n",
    "        #print(score.shape)\n",
    "        return score\n",
    "\n",
    "disc2 = Discriminator2().to(device)\n",
    "disc2 = disc2.float()\n",
    "print(disc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the optimizers and loss functions \n",
    "gen_optimizer = torch.optim.Adam(gen.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
    "disc1_optimizer = torch.optim.Adam(disc1.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
    "disc2_optimizer = torch.optim.Adam(disc2.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
    "#l2_loss   = nn.MSELoss() #MSEloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0],step: [100], mri_ssim_loss: [0.98275131], pet_ssim_loss: [0.97381878], gen_loss: [7.25000858], disc_loss: [nan]\n",
      "Epoch: [ 0],step: [200], mri_ssim_loss: [1.05526340], pet_ssim_loss: [1.09247267], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 1],step: [300], mri_ssim_loss: [0.99793130], pet_ssim_loss: [0.99350160], gen_loss: [6.88475800], disc_loss: [nan]\n",
      "Epoch: [ 1],step: [400], mri_ssim_loss: [0.97720635], pet_ssim_loss: [0.95596385], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 1],step: [500], mri_ssim_loss: [1.13062871], pet_ssim_loss: [1.10033822], gen_loss: [nan], disc_loss: [7.43722296]\n",
      "Epoch: [ 2],step: [600], mri_ssim_loss: [1.01831174], pet_ssim_loss: [1.04639339], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 2],step: [700], mri_ssim_loss: [1.02742219], pet_ssim_loss: [1.06731546], gen_loss: [nan], disc_loss: [2.54065228]\n",
      "Epoch: [ 2],step: [800], mri_ssim_loss: [1.04938662], pet_ssim_loss: [1.03140306], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 3],step: [900], mri_ssim_loss: [0.99110031], pet_ssim_loss: [1.03514707], gen_loss: [5.22667408], disc_loss: [nan]\n",
      "Epoch: [ 3],step: [1000], mri_ssim_loss: [1.07644832], pet_ssim_loss: [1.08622026], gen_loss: [5.92070675], disc_loss: [nan]\n",
      "Epoch: [ 4],step: [1100], mri_ssim_loss: [0.97837096], pet_ssim_loss: [1.09427142], gen_loss: [nan], disc_loss: [2.51311302]\n",
      "Epoch: [ 4],step: [1200], mri_ssim_loss: [1.00426185], pet_ssim_loss: [0.99830335], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 4],step: [1300], mri_ssim_loss: [1.01625466], pet_ssim_loss: [0.96022785], gen_loss: [nan], disc_loss: [3.71414161]\n",
      "Epoch: [ 5],step: [1400], mri_ssim_loss: [1.00787985], pet_ssim_loss: [1.05582201], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 5],step: [1500], mri_ssim_loss: [0.29228103], pet_ssim_loss: [0.28314215], gen_loss: [6.21418715], disc_loss: [5.34728289]\n",
      "Epoch: [ 5],step: [1600], mri_ssim_loss: [0.98875970], pet_ssim_loss: [1.01952100], gen_loss: [6.88359213], disc_loss: [nan]\n",
      "Epoch: [ 6],step: [1700], mri_ssim_loss: [0.94948912], pet_ssim_loss: [1.02531576], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 6],step: [1800], mri_ssim_loss: [0.92944121], pet_ssim_loss: [0.86810511], gen_loss: [nan], disc_loss: [2.48959708]\n",
      "Epoch: [ 6],step: [1900], mri_ssim_loss: [0.94177461], pet_ssim_loss: [0.79197431], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 7],step: [2000], mri_ssim_loss: [0.98486537], pet_ssim_loss: [0.88025635], gen_loss: [6.65198231], disc_loss: [nan]\n",
      "Epoch: [ 7],step: [2100], mri_ssim_loss: [0.95931369], pet_ssim_loss: [0.76310468], gen_loss: [nan], disc_loss: [3.23626924]\n",
      "Epoch: [ 8],step: [2200], mri_ssim_loss: [0.99405760], pet_ssim_loss: [0.75650513], gen_loss: [5.31894016], disc_loss: [nan]\n",
      "Epoch: [ 8],step: [2300], mri_ssim_loss: [1.00975978], pet_ssim_loss: [0.99015087], gen_loss: [9.68986702], disc_loss: [nan]\n",
      "Epoch: [ 8],step: [2400], mri_ssim_loss: [0.87883037], pet_ssim_loss: [0.98055184], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [ 9],step: [2500], mri_ssim_loss: [0.97576624], pet_ssim_loss: [1.05204153], gen_loss: [6.95363474], disc_loss: [nan]\n",
      "Epoch: [ 9],step: [2600], mri_ssim_loss: [1.00985825], pet_ssim_loss: [1.02137685], gen_loss: [8.03125381], disc_loss: [nan]\n",
      "Epoch: [ 9],step: [2700], mri_ssim_loss: [0.97402322], pet_ssim_loss: [0.94763118], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [10],step: [2800], mri_ssim_loss: [0.99047995], pet_ssim_loss: [1.00298119], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [10],step: [2900], mri_ssim_loss: [1.04231501], pet_ssim_loss: [1.05534756], gen_loss: [4.58989811], disc_loss: [7.36252832]\n",
      "Epoch: [11],step: [3000], mri_ssim_loss: [1.04754293], pet_ssim_loss: [1.13985884], gen_loss: [nan], disc_loss: [4.43808079]\n",
      "Epoch: [11],step: [3100], mri_ssim_loss: [1.00050867], pet_ssim_loss: [0.99633068], gen_loss: [nan], disc_loss: [3.32783985]\n",
      "Epoch: [11],step: [3200], mri_ssim_loss: [0.97080517], pet_ssim_loss: [0.95984399], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [12],step: [3300], mri_ssim_loss: [0.97630066], pet_ssim_loss: [0.99580079], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [12],step: [3400], mri_ssim_loss: [0.99353999], pet_ssim_loss: [0.96161658], gen_loss: [nan], disc_loss: [3.64179492]\n",
      "Epoch: [12],step: [3500], mri_ssim_loss: [0.90956354], pet_ssim_loss: [0.88015479], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [13],step: [3600], mri_ssim_loss: [0.93340284], pet_ssim_loss: [0.85282409], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [13],step: [3700], mri_ssim_loss: [0.96421695], pet_ssim_loss: [0.88020849], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [13],step: [3800], mri_ssim_loss: [0.98584020], pet_ssim_loss: [0.88848811], gen_loss: [nan], disc_loss: [6.23833323]\n",
      "Epoch: [14],step: [3900], mri_ssim_loss: [0.99504030], pet_ssim_loss: [0.93683749], gen_loss: [nan], disc_loss: [3.85707879]\n",
      "Epoch: [14],step: [4000], mri_ssim_loss: [0.97073752], pet_ssim_loss: [0.83894104], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [15],step: [4100], mri_ssim_loss: [0.83492804], pet_ssim_loss: [0.94336033], gen_loss: [nan], disc_loss: [2.23197675]\n",
      "Epoch: [15],step: [4200], mri_ssim_loss: [0.96711922], pet_ssim_loss: [0.96491700], gen_loss: [6.66349363], disc_loss: [nan]\n",
      "Epoch: [15],step: [4300], mri_ssim_loss: [0.89438510], pet_ssim_loss: [0.88489252], gen_loss: [6.68513393], disc_loss: [nan]\n",
      "Epoch: [16],step: [4400], mri_ssim_loss: [0.89215422], pet_ssim_loss: [0.99124902], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [16],step: [4500], mri_ssim_loss: [0.86286038], pet_ssim_loss: [0.97979653], gen_loss: [nan], disc_loss: [2.79836464]\n",
      "Epoch: [16],step: [4600], mri_ssim_loss: [0.89138740], pet_ssim_loss: [0.98580074], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [17],step: [4700], mri_ssim_loss: [0.89271337], pet_ssim_loss: [0.94223589], gen_loss: [6.02944708], disc_loss: [nan]\n",
      "Epoch: [17],step: [4800], mri_ssim_loss: [0.94423115], pet_ssim_loss: [0.92517120], gen_loss: [4.50215816], disc_loss: [4.61839581]\n",
      "Epoch: [18],step: [4900], mri_ssim_loss: [0.96352023], pet_ssim_loss: [0.85766888], gen_loss: [nan], disc_loss: [3.82458758]\n",
      "Epoch: [18],step: [5000], mri_ssim_loss: [0.97936624], pet_ssim_loss: [0.91661543], gen_loss: [7.33310986], disc_loss: [nan]\n",
      "Epoch: [18],step: [5100], mri_ssim_loss: [0.91361636], pet_ssim_loss: [0.85234767], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [19],step: [5200], mri_ssim_loss: [0.91929120], pet_ssim_loss: [0.86739892], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [19],step: [5300], mri_ssim_loss: [0.97436672], pet_ssim_loss: [0.93361050], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [19],step: [5400], mri_ssim_loss: [0.89405096], pet_ssim_loss: [0.90496784], gen_loss: [5.23959398], disc_loss: [5.56653118]\n",
      "Epoch: [20],step: [5500], mri_ssim_loss: [0.89973146], pet_ssim_loss: [0.87159348], gen_loss: [nan], disc_loss: [2.44778848]\n",
      "Epoch: [20],step: [5600], mri_ssim_loss: [0.97340435], pet_ssim_loss: [0.85501873], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [20],step: [5700], mri_ssim_loss: [0.98520029], pet_ssim_loss: [0.95767266], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [21],step: [5800], mri_ssim_loss: [0.99066305], pet_ssim_loss: [0.92172122], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [21],step: [5900], mri_ssim_loss: [0.92908764], pet_ssim_loss: [0.82856160], gen_loss: [4.61653662], disc_loss: [nan]\n",
      "Epoch: [22],step: [6000], mri_ssim_loss: [1.00333643], pet_ssim_loss: [0.79346746], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [22],step: [6100], mri_ssim_loss: [0.98233390], pet_ssim_loss: [0.92524797], gen_loss: [4.02021027], disc_loss: [nan]\n",
      "Epoch: [22],step: [6200], mri_ssim_loss: [1.01298869], pet_ssim_loss: [0.88241893], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [23],step: [6300], mri_ssim_loss: [1.01511884], pet_ssim_loss: [0.82775760], gen_loss: [4.93405199], disc_loss: [3.84005284]\n",
      "Epoch: [23],step: [6400], mri_ssim_loss: [0.97208518], pet_ssim_loss: [0.81781703], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [23],step: [6500], mri_ssim_loss: [0.98399568], pet_ssim_loss: [0.89838082], gen_loss: [4.24322224], disc_loss: [5.13457632]\n",
      "Epoch: [24],step: [6600], mri_ssim_loss: [0.96675181], pet_ssim_loss: [0.81555450], gen_loss: [6.57896566], disc_loss: [nan]\n",
      "Epoch: [24],step: [6700], mri_ssim_loss: [0.96941870], pet_ssim_loss: [0.89096290], gen_loss: [nan], disc_loss: [5.37230730]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [24],step: [6800], mri_ssim_loss: [0.94006497], pet_ssim_loss: [0.93713683], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [25],step: [6900], mri_ssim_loss: [0.97336388], pet_ssim_loss: [0.94279027], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [25],step: [7000], mri_ssim_loss: [0.92244852], pet_ssim_loss: [0.85726213], gen_loss: [4.39884186], disc_loss: [nan]\n",
      "Epoch: [26],step: [7100], mri_ssim_loss: [0.96547002], pet_ssim_loss: [0.81897056], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [26],step: [7200], mri_ssim_loss: [0.98333991], pet_ssim_loss: [0.93523610], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [26],step: [7300], mri_ssim_loss: [0.96276587], pet_ssim_loss: [0.88682091], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [27],step: [7400], mri_ssim_loss: [0.91923845], pet_ssim_loss: [0.89240211], gen_loss: [nan], disc_loss: [3.05655622]\n",
      "Epoch: [27],step: [7500], mri_ssim_loss: [0.94408119], pet_ssim_loss: [0.88941497], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [27],step: [7600], mri_ssim_loss: [0.94182861], pet_ssim_loss: [0.87079138], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [28],step: [7700], mri_ssim_loss: [0.98494703], pet_ssim_loss: [0.92026228], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [28],step: [7800], mri_ssim_loss: [0.89606965], pet_ssim_loss: [0.86872339], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [29],step: [7900], mri_ssim_loss: [0.96010727], pet_ssim_loss: [0.89631087], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [29],step: [8000], mri_ssim_loss: [0.97540456], pet_ssim_loss: [0.93773854], gen_loss: [3.15324473], disc_loss: [nan]\n",
      "Epoch: [29],step: [8100], mri_ssim_loss: [0.94699365], pet_ssim_loss: [0.92051423], gen_loss: [nan], disc_loss: [4.02321815]\n",
      "Epoch: [30],step: [8200], mri_ssim_loss: [0.95607048], pet_ssim_loss: [0.82552111], gen_loss: [5.39228249], disc_loss: [nan]\n",
      "Epoch: [30],step: [8300], mri_ssim_loss: [0.99537754], pet_ssim_loss: [0.97735500], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [30],step: [8400], mri_ssim_loss: [0.89895314], pet_ssim_loss: [0.88985181], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [31],step: [8500], mri_ssim_loss: [0.92674154], pet_ssim_loss: [0.85024291], gen_loss: [5.25639153], disc_loss: [nan]\n",
      "Epoch: [31],step: [8600], mri_ssim_loss: [0.95415831], pet_ssim_loss: [0.88904709], gen_loss: [nan], disc_loss: [5.03878832]\n",
      "Epoch: [31],step: [8700], mri_ssim_loss: [0.95090997], pet_ssim_loss: [0.90297097], gen_loss: [7.23290348], disc_loss: [nan]\n",
      "Epoch: [32],step: [8800], mri_ssim_loss: [0.97621101], pet_ssim_loss: [0.93854427], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [32],step: [8900], mri_ssim_loss: [0.93263924], pet_ssim_loss: [0.85654932], gen_loss: [5.33692932], disc_loss: [3.67821121]\n",
      "Epoch: [33],step: [9000], mri_ssim_loss: [0.92937940], pet_ssim_loss: [0.82004082], gen_loss: [nan], disc_loss: [3.78372288]\n",
      "Epoch: [33],step: [9100], mri_ssim_loss: [0.97963655], pet_ssim_loss: [0.93335062], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [33],step: [9200], mri_ssim_loss: [0.94154745], pet_ssim_loss: [0.84583330], gen_loss: [3.85298896], disc_loss: [nan]\n",
      "Epoch: [34],step: [9300], mri_ssim_loss: [0.97576660], pet_ssim_loss: [0.82790780], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [34],step: [9400], mri_ssim_loss: [0.96599597], pet_ssim_loss: [0.93955821], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [34],step: [9500], mri_ssim_loss: [0.91543627], pet_ssim_loss: [0.84999675], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [35],step: [9600], mri_ssim_loss: [0.98337978], pet_ssim_loss: [0.93022126], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [35],step: [9700], mri_ssim_loss: [0.91823131], pet_ssim_loss: [0.88601607], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [36],step: [9800], mri_ssim_loss: [0.93072832], pet_ssim_loss: [0.86000562], gen_loss: [5.96828985], disc_loss: [nan]\n",
      "Epoch: [36],step: [9900], mri_ssim_loss: [0.97323030], pet_ssim_loss: [0.93499559], gen_loss: [3.53345919], disc_loss: [nan]\n",
      "Epoch: [36],step: [10000], mri_ssim_loss: [0.91774166], pet_ssim_loss: [0.83971733], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [37],step: [10100], mri_ssim_loss: [0.96485680], pet_ssim_loss: [0.80517131], gen_loss: [7.34310150], disc_loss: [2.89042115]\n",
      "Epoch: [37],step: [10200], mri_ssim_loss: [0.99240744], pet_ssim_loss: [0.95471704], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [37],step: [10300], mri_ssim_loss: [0.91981775], pet_ssim_loss: [0.86526239], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [38],step: [10400], mri_ssim_loss: [0.95855540], pet_ssim_loss: [0.82028210], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [38],step: [10500], mri_ssim_loss: [0.95758492], pet_ssim_loss: [0.84756887], gen_loss: [nan], disc_loss: [3.43855548]\n",
      "Epoch: [38],step: [10600], mri_ssim_loss: [0.91561455], pet_ssim_loss: [0.85492718], gen_loss: [nan], disc_loss: [5.97106600]\n",
      "Epoch: [39],step: [10700], mri_ssim_loss: [0.98170489], pet_ssim_loss: [0.92117882], gen_loss: [nan], disc_loss: [2.39920211]\n",
      "Epoch: [39],step: [10800], mri_ssim_loss: [0.96608561], pet_ssim_loss: [0.83611196], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [40],step: [10900], mri_ssim_loss: [0.99887437], pet_ssim_loss: [0.96018326], gen_loss: [5.11257362], disc_loss: [nan]\n",
      "Epoch: [40],step: [11000], mri_ssim_loss: [1.01965737], pet_ssim_loss: [0.95150763], gen_loss: [nan], disc_loss: [3.64226508]\n",
      "Epoch: [40],step: [11100], mri_ssim_loss: [1.11005151], pet_ssim_loss: [1.09380198], gen_loss: [nan], disc_loss: [3.01836181]\n",
      "Epoch: [41],step: [11200], mri_ssim_loss: [1.03209889], pet_ssim_loss: [1.14152920], gen_loss: [nan], disc_loss: [3.63167119]\n",
      "Epoch: [41],step: [11300], mri_ssim_loss: [1.08001113], pet_ssim_loss: [1.12522137], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [41],step: [11400], mri_ssim_loss: [1.06843638], pet_ssim_loss: [1.12183070], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [42],step: [11500], mri_ssim_loss: [1.02115917], pet_ssim_loss: [1.10712850], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [42],step: [11600], mri_ssim_loss: [1.01826489], pet_ssim_loss: [1.07806599], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [43],step: [11700], mri_ssim_loss: [1.03482211], pet_ssim_loss: [1.08868968], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [43],step: [11800], mri_ssim_loss: [0.99676776], pet_ssim_loss: [1.05077541], gen_loss: [nan], disc_loss: [4.37851715]\n",
      "Epoch: [43],step: [11900], mri_ssim_loss: [1.03048515], pet_ssim_loss: [1.08956671], gen_loss: [nan], disc_loss: [2.22702765]\n",
      "Epoch: [44],step: [12000], mri_ssim_loss: [1.03136253], pet_ssim_loss: [1.04962945], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [44],step: [12100], mri_ssim_loss: [0.99894273], pet_ssim_loss: [0.93818521], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [44],step: [12200], mri_ssim_loss: [1.02009511], pet_ssim_loss: [0.98569459], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [45],step: [12300], mri_ssim_loss: [1.01965356], pet_ssim_loss: [1.05537701], gen_loss: [nan], disc_loss: [2.21907806]\n",
      "Epoch: [45],step: [12400], mri_ssim_loss: [1.01115561], pet_ssim_loss: [0.96506065], gen_loss: [8.46032429], disc_loss: [nan]\n",
      "Epoch: [45],step: [12500], mri_ssim_loss: [0.99506515], pet_ssim_loss: [0.95522279], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [46],step: [12600], mri_ssim_loss: [1.00200641], pet_ssim_loss: [0.93871814], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [46],step: [12700], mri_ssim_loss: [1.00792277], pet_ssim_loss: [0.96884084], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [47],step: [12800], mri_ssim_loss: [1.02076459], pet_ssim_loss: [0.98076755], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [47],step: [12900], mri_ssim_loss: [0.99850678], pet_ssim_loss: [0.93222600], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [47],step: [13000], mri_ssim_loss: [1.06391239], pet_ssim_loss: [1.04125226], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [48],step: [13100], mri_ssim_loss: [1.03661788], pet_ssim_loss: [1.03248501], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [48],step: [13200], mri_ssim_loss: [1.03035283], pet_ssim_loss: [1.02734804], gen_loss: [nan], disc_loss: [5.98230124]\n",
      "Epoch: [48],step: [13300], mri_ssim_loss: [1.00342548], pet_ssim_loss: [0.96551025], gen_loss: [nan], disc_loss: [3.65829730]\n",
      "Epoch: [49],step: [13400], mri_ssim_loss: [1.02528727], pet_ssim_loss: [1.03732526], gen_loss: [nan], disc_loss: [nan]\n",
      "Epoch: [49],step: [13500], mri_ssim_loss: [1.01447213], pet_ssim_loss: [0.98992980], gen_loss: [nan], disc_loss: [nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [49],step: [13600], mri_ssim_loss: [1.01977551], pet_ssim_loss: [0.93285632], gen_loss: [4.75679302], disc_loss: [5.82357693]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Generator. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'disc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-8178bead5375>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;31m#Save a checkpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/DDcGAN/checkpoint_gen.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/DDcGAN/checkpoint_disc.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'disc' is not defined"
     ]
    }
   ],
   "source": [
    "# perform the training\n",
    "counter = 0\n",
    "Tensor = torch.cuda.FloatTensor if device else torch.FloatTensor\n",
    "# Adversarial ground truths\n",
    "one = Tensor(np.ones((1)))\n",
    "start_time = time.time()\n",
    "lamda = 1\n",
    "ep_ssim_mri_loss = []\n",
    "ep_ssim_pet_loss = []\n",
    "ep_adv_loss = []\n",
    "ep_disc_loss = []\n",
    "ep_gen_loss =[]\n",
    "for epoch in range(EPOCH):\n",
    "    ssim_mri_Loss = []\n",
    "    ssim_pet_Loss   = []\n",
    "    adv_Loss = []\n",
    "    gen_Loss = []\n",
    "    disc_Loss = []\n",
    "    #run batch images\n",
    "    batch_idxs = 272 // batch_size\n",
    "    for idx in range(0, batch_idxs):\n",
    "        #ge tthe mri and pet batches\n",
    "        b_x = train_mri_tensor[idx*batch_size : (idx+1)*batch_size,:,:,:].to(device)\n",
    "        b_y = train_pet_tensor[idx*batch_size : (idx+1)*batch_size,:,:,:].to(device)\n",
    "        counter += 1\n",
    "        \n",
    "        #clear the generator gradients\n",
    "        gen_optimizer.zero_grad()    \n",
    "\n",
    "        #get a fused image from generator\n",
    "        output = gen(b_x,b_y)               # gen output\n",
    "        \n",
    "        #feed the fused image into the discriminator 1 and 2\n",
    "        fused_disc_score1 = disc1(output)\n",
    "        fused_disc_score2 = disc2(output)        \n",
    "        \n",
    "        #define the generator loss\n",
    "        ssim_loss_mri = 1 - ssim(output, b_x,data_range=1)\n",
    "        ssim_loss_pet = 1 - ssim(output, b_y,data_range=1)\n",
    "        ssim_loss = ssim_loss_mri + ssim_loss_pet\n",
    "        adv_loss1 = -torch.mean(torch.log(fused_disc_score1))\n",
    "        adv_loss2 = -torch.mean(torch.log(fused_disc_score2))\n",
    "        gen_loss = ssim_loss + adv_loss1 + adv_loss2\n",
    "        \n",
    "        #update the generator\n",
    "        gen_loss.backward(retain_graph=True)                 # backpropagation, compute gradients\n",
    "        gen_optimizer.step()                # apply gradients\n",
    "        \n",
    "        #clear the discriminator gradients\n",
    "        disc1_optimizer.zero_grad()  \n",
    "        disc2_optimizer.zero_grad()      \n",
    "        \n",
    "        #feed the MRI image and PET images into the discriminator 1 and 2 respectively\n",
    "        mri_disc_score = disc1(b_x.detach())\n",
    "        pet_disc_score = disc2(b_y.detach())\n",
    "        \n",
    "        #define the discriminator loss\n",
    "        disc1_real = -torch.mean(torch.log(mri_disc_score))\n",
    "        disc2_real = -torch.mean(torch.log(pet_disc_score))\n",
    "        disc1_fake = -torch.mean(torch.log(one - fused_disc_score1))\n",
    "        disc2_fake = -torch.mean(torch.log(one - fused_disc_score2))\n",
    "        disc_loss = disc1_real + disc2_real + disc1_fake + disc2_fake\n",
    "        \n",
    "        #update the discriminator\n",
    "        disc_loss.backward()                 # backpropagation, compute gradients\n",
    "        disc1_optimizer.step()                # apply gradients  \n",
    "        disc2_optimizer.step()                # apply gradients \n",
    "\n",
    "        #store all the loss values at each epoch\n",
    "        ssim_mri_Loss.append(ssim_loss_mri.item())\n",
    "        ssim_pet_Loss.append(ssim_loss_pet.item())\n",
    "        gen_Loss.append(gen_loss.item())\n",
    "        disc_Loss.append(disc_loss.item())\n",
    "        if counter % 100 == 0:\n",
    "            print(\"Epoch: [%2d],step: [%2d], mri_ssim_loss: [%.8f], pet_ssim_loss: [%.8f], gen_loss: [%.8f], disc_loss: [%.8f]\" \n",
    "            %(epoch, counter, ssim_loss_mri, ssim_loss_pet, gen_loss, disc_loss))\n",
    "    \n",
    "    av_ssim_mri_loss = np.average(ssim_mri_Loss)\n",
    "    ep_ssim_mri_loss.append(av_ssim_mri_loss)\n",
    "    \n",
    "    av_ssim_pet_loss = np.average(ssim_pet_Loss)\n",
    "    ep_ssim_pet_loss.append(av_ssim_pet_loss)\n",
    "    \n",
    "    av_gen_loss = np.average(gen_Loss)\n",
    "    ep_gen_loss.append(av_gen_loss)\n",
    "    \n",
    "    av_disc_loss = np.average(disc_Loss)\n",
    "    ep_disc_loss.append(av_disc_loss)\n",
    "    \n",
    "    if(epoch == EPOCH -1):\n",
    "        #Save a checkpoint\n",
    "        torch.save(gen, 'C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/DDcGAN/checkpoint_gen.pth') \n",
    "        torch.save(disc, 'C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/DDcGAN/checkpoint_disc.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = np.asarray(ep_ssim_mri_loss)\n",
    "l2 = np.asarray(ep_ssim_pet_loss)\n",
    "l4 = np.asarray(ep_gen_loss)\n",
    "l5 = np.asarray(ep_disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('C:/Users/horan/Desktop/Suraka/Loss curves/DDcGAN/H5 Files/Loss_GEN.h5', 'w')\n",
    "h5f.create_dataset('MRI_dataset', data=l4)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21a082f35f8>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(l1)\n",
    "#plt.savefig('C:/Users/horan/Desktop/Suraka/Loss curves/VIFNet/Loss curves/SSIM_MRI_loss_curve.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test input MRI dataset\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/MRI/')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/MRI/')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "test_mri = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    test_mri[i,:,:] =(imageio.imread(data[i]))\n",
    "    test_mri[i,:,:] =(test_mri[i,:,:] - np.min(test_mri[i,:,:])) / (np.max(test_mri[i,:,:]) - np.min(test_mri[i,:,:]))\n",
    "    test_mri[i,:,:] = np.float32(test_mri[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "test_mri = np.expand_dims(test_mri,axis=1)\n",
    "#verify the shape matches the pytorch standard\n",
    "test_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the test mri image\n",
    "#test_mri = test_mri[0,:,:,:]\n",
    "#test_mri = np.expand_dims(test_mri,axis=0)\n",
    "plt.imshow(test_mri[0,0,:,:],'gray')\n",
    "#plt.savefig('MRI.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the MRI Testing data to pytorch tensor\n",
    "test_mri_tensor = torch.from_numpy(test_mri).float()\n",
    "print(test_mri_tensor.shape)\n",
    "test_mri_tensor.requires_grad =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test input PET dataset\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/PET/')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/PET/')\n",
    "data = glob.glob(os.path.join(dataset, \"*.png\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "test_pet = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    test_pet[i,:,:] =(imageio.imread(data[i]))\n",
    "    test_pet[i,:,:] =(test_pet[i,:,:] - np.min(test_pet[i,:,:])) / (np.max(test_pet[i,:,:]) - np.min(test_pet[i,:,:]))\n",
    "    test_pet[i,:,:] = np.float32(test_pet[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "test_pet = np.expand_dims(test_pet,axis=1)\n",
    "#verify the shape matches the pytorch standard\n",
    "test_pet.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the test pet image\n",
    "#test_pet = test_pet[2,:,:,:]\n",
    "#test_pet = np.expand_dims(test_pet,axis=0)\n",
    "plt.imshow(test_pet[0,0,:,:],'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_pet[0,0,:,:],'gray')\n",
    "#plt.savefig('PET.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the MRI Testing data to pytorch tensor\n",
    "test_pet_tensor = torch.from_numpy(test_pet).float()\n",
    "print(test_pet_tensor.shape)\n",
    "test_pet_tensor.requires_grad =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gen =torch.load('C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/FuseGAN/checkpoint_gen.pth')\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted the fused image\n",
    "fused = gen(test_mri_tensor.to(device), test_pet_tensor.to(device))\n",
    "fused_numpy = fused.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the output image\n",
    "plt.imshow(fused_numpy[0,0,:,:],'gray')\n",
    "#plt.savefig('Fused.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imageio.imwrite('C:/Users/horan/Desktop/Suraka/Fused/Fused.png',np.uint8(cv2.normalize(fused_numpy[0,0,:,:], None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the guidance image for MRI and PET wrt to the fused image\n",
    "time1 = time.time()\n",
    "count = 0 \n",
    "guide_fuse_mri = np.zeros((256,256),dtype=float)\n",
    "guide_fuse_pet = np.zeros((256,256),dtype=float)\n",
    "\n",
    "for y_coord in range(0,256):\n",
    "    for x_coord in range(0,256):\n",
    "        jacob_fuse_mri = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_mri_tensor, retain_graph=True, create_graph=True)[0]\n",
    "        jacob_numpy_mri = np.squeeze(jacob_fuse_mri.data.cpu().numpy())  \n",
    "        guide_fuse_mri[y_coord,x_coord] = jacob_numpy_mri[y_coord,x_coord]\n",
    "        jacob_fuse_pet = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_pet_tensor, retain_graph=True, create_graph=True)[0]\n",
    "        jacob_numpy_pet = np.squeeze(jacob_fuse_pet.data.cpu().numpy())  \n",
    "        guide_fuse_pet[y_coord,x_coord] = jacob_numpy_pet[y_coord,x_coord]\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print('Count is %d' %count)\n",
    "time2 = time.time()\n",
    "print('Time taken to compute is %d seconds' %(time2-time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "plt.colorbar()\n",
    "#plt.savefig('Jacob_Fused_MRI.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guide_fuse_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "#plt.colorbar()\n",
    "#plt.savefig('Jacob_Fused_PET.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guide_fuse_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(fused_RGB)\n",
    "#plt.savefig('Fused_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(mri_RGB)\n",
    "#plt.savefig('MRI_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(pet_RGB)\n",
    "#plt.savefig('PET_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5f = h5py.File('C:/Users/horan/Desktop/Suraka/Jacobian_MRI.h5', 'w')\n",
    "#h5f.create_dataset('MRI_dataset', data=guide_fuse_mri)\n",
    "#h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5f = h5py.File('C:/Users/horan/Desktop/Suraka/Jacobian_PET.h5', 'w')\n",
    "#h5f.create_dataset('PET_dataset', data=guide_fuse_pet)\n",
    "#h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/H5 Files/Jacobian_MRI.h5', 'r')\n",
    "guide_fuse_mri =  np.array(hf.get('MRI_dataset'))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/H5 Files/Jacobian_PET.h5', 'r')\n",
    "guide_fuse_pet =  np.array(hf.get('PET_dataset'))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define overlay images\n",
    "fused_RGB = np.zeros((256,256,3),dtype=float)\n",
    "mri_RGB   = np.zeros((256,256,3),dtype=float)\n",
    "pet_RGB   = np.zeros((256,256,3),dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_RGB[:,:,0]  = guide_fuse_mri \n",
    "fused_RGB[:,:,1]  = guide_fuse_pet \n",
    "fused_RGB[:,:,2]  = fused_numpy[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fused_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_RGB[:,:,0]  = guide_fuse_mri\n",
    "mri_RGB[:,:,1]  = guide_fuse_pet \n",
    "mri_RGB[:,:,2]  = test_mri[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mri_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_RGB[:,:,0]  = guide_fuse_mri\n",
    "pet_RGB[:,:,1]  = guide_fuse_pet \n",
    "pet_RGB[:,:,2]  = test_pet[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pet_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the window\n",
    "root = Tk()  \n",
    "root.title('Visualisation of fusion networks')\n",
    "root.configure(background='white')\n",
    "\n",
    "\n",
    "#Label the images\n",
    "#fontStyle = tkFont.Font(family=\"Lucida Grande\", size=15)\n",
    "#w1 = tk.Label(root, bg='white', font=fontStyle, text=\"Fused Image\")\n",
    "#w1.grid(row=0, column=1)\n",
    "#w1.pack()\n",
    "\n",
    "#define the frame\n",
    "canvasframe = Frame(root)  # define Input and output frame\n",
    "buttonframe = Frame(root)  # define button frame\n",
    "canvasframe.pack()  # pack the Input and Output frame\n",
    "buttonframe.pack()  # pack the button frame\n",
    "\n",
    "\n",
    "#define the canvas\n",
    "canvas = Canvas(canvasframe, width=1800, height=920, bg = 'white')\n",
    "canvas.grid(row=0, column=0)\n",
    "\n",
    "#Insert fused image to the canvas\n",
    "img_fused = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/Fused/Fused.png\") # load the image\n",
    "canvas.create_image(0, 0, image=img_fused, anchor=NW)\n",
    "\n",
    "#Insert MRI image to the canvas\n",
    "img_mri = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/MRI/MRI.gif\") # load the image\n",
    "canvas.create_image(620, 0, image=img_mri, anchor=NW)\n",
    "\n",
    "#Insert PET image to the canvas\n",
    "img_pet = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/PET/3.png\") # load the image\n",
    "canvas.create_image(1240, 0, image=img_pet, anchor=NW)\n",
    "\n",
    "def start_mouseover():  # function called when user clicks the button \n",
    "    # link the function to the left-mouse-click event\n",
    "    canvas.bind(\"<B1-Motion>\", Coordinates)\n",
    "\n",
    "def Coordinates(event): # function called when left-mouse-button is clicked with a mouseover\n",
    "    x_coord = event.x  # save x and y coordinates selected by the user   \n",
    "    y_coord = event.y\n",
    "    print('mouse position is at' + '(' + str(y_coord) + ',' + str(x_coord) + ')', end='\\r')\n",
    "    #display the output MRI Jacobian image\n",
    "    #img_MR_out = ImageTk.PhotoImage(file ='C:/Users/cgvadmin/Desktop/Suraka/Fused_MRI/im_' + str(y_coord) + '_' + str(x_coord) + '.png') # load the image\n",
    "    jacobian_fuse_mri = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_mri_tensor, retain_graph=True, create_graph=True)[0]\n",
    "    jacobian_fuse_pet = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_pet_tensor, retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    jacob_val_mri = np.squeeze(jacobian_fuse_mri.data.cpu().numpy())    \n",
    "    jacob_val_pet = np.squeeze(jacobian_fuse_pet.data.cpu().numpy())\n",
    "    \n",
    "    x_mri = np.asarray(np.where(np.any(jacob_val_mri, axis = 0)))\n",
    "    y_mri = np.asarray(np.where(np.any(jacob_val_mri, axis = 1)))\n",
    "    minx_mri, maxx_mri, miny_mri, maxy_mri = np.min(x_mri), np.max(x_mri), np.min(y_mri), np.max(y_mri)  #return min and max coordinates\n",
    "    zoom_im_mri = jacob_val_mri[miny_mri:maxy_mri,minx_mri:maxx_mri] \n",
    "    \n",
    "    x_pet = np.asarray(np.where(np.any(jacob_val_pet, axis = 0)))\n",
    "    y_pet = np.asarray(np.where(np.any(jacob_val_pet, axis = 1)))\n",
    "    minx_pet, maxx_pet, miny_pet, maxy_pet = np.min(x_pet), np.max(x_pet), np.min(y_pet), np.max(y_pet)  #return min and max coordinates\n",
    "    zoom_im_pet = jacob_val_pet[miny_pet:maxy_pet,minx_pet:maxx_pet] \n",
    "    \n",
    "    plt.imshow(fused_numpy[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom Fused')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo11.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out11 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo11.png')\n",
    "    canvas.create_image(320,0,image=im_out11,anchor=NW)\n",
    "    canvas.image11 = im_out11\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(test_mri[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom MRI')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo12.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out12 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo12.png')\n",
    "    canvas.create_image(950,0,image=im_out12,anchor=NW)\n",
    "    canvas.image12 = im_out12\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(test_pet[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom PET')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo13.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out13 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo13.png')\n",
    "    canvas.create_image(1500,0,image=im_out13,anchor=NW)\n",
    "    canvas.image13 = im_out13\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(jacob_val_mri,cmap='viridis', aspect ='equal')\n",
    "    plt.title('Fused wrt MRI')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo1.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out1 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo1.png')\n",
    "    canvas.create_image(0,320,image=im_out1,anchor=NW)\n",
    "    canvas.image1 = im_out1\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    #f.add_subplot(1,5,2)\n",
    "    plt.imshow(zoom_im_mri,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Zoomed (Fused wrt MRI)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo2.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out2 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo2.png')\n",
    "    canvas.create_image(280,320,image=im_out2,anchor=NW)\n",
    "    canvas.image2 = im_out2\n",
    "    #plt.tight_layout()\n",
    "    #divider = make_axes_locatable(plt)\n",
    "    #cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    #plt.colorbar(cax=cax)\n",
    "    \n",
    "    #f.add_subplot(1,5,3)\n",
    "    plt.xlim(0,0.7)\n",
    "    plt.ylim(0,0.7)\n",
    "    plt.plot(jacob_val_mri[y_coord,x_coord],jacob_val_pet[y_coord,x_coord],'-ro')\n",
    "    plt.xlabel('MRI pixel score (Fused wrt MRI)')\n",
    "    plt.ylabel('PET pixel score (Fused wrt PET)')\n",
    "    plt.title('Mouse position at: (' + str(y_coord) + ',' + str(x_coord) + ')')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.draw()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo3.png', bbox_inches = 'tight',pad_inches = 0.1)\n",
    "    plt.close()\n",
    "    im_out3 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo3.png')\n",
    "    canvas.create_image(600,320,image=im_out3,anchor=NW)\n",
    "    canvas.image3 = im_out3\n",
    "    \n",
    "    #f.add_subplot(1,5,4)\n",
    "    plt.imshow(jacob_val_pet,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Fused wrt PET')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo4.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out4 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo4.png')\n",
    "    canvas.create_image(900,320,image=im_out4,anchor=NW)\n",
    "    canvas.image4 = im_out4\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    #f.add_subplot(1,5,5)\n",
    "    plt.imshow(zoom_im_pet,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Zoomed (Fused wrt PET)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo5.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out5 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo5.png')\n",
    "    canvas.create_image(1180,320,image=im_out5,anchor=NW)\n",
    "    canvas.image5 = im_out5\n",
    "\n",
    "    plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "    plt.title('Fused wrt MRI')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo6.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out6 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo6.png')\n",
    "    canvas.create_image(0,650,image=im_out6,anchor=NW)\n",
    "    canvas.image6 = im_out6\n",
    "    \n",
    "    plt.imshow(fused_RGB)\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo8.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out8 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo8.png')\n",
    "    canvas.create_image(300,650,image=im_out8,anchor=NW)\n",
    "    canvas.image8 = im_out8\n",
    "    \n",
    "    plt.imshow(mri_RGB)\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo9.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out9 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo9.png')\n",
    "    canvas.create_image(600,650,image=im_out9,anchor=NW)\n",
    "    canvas.image9 = im_out9\n",
    "    \n",
    "    plt.imshow(pet_RGB)\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo10.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out10 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo10.png')\n",
    "    canvas.create_image(900,650,image=im_out10,anchor=NW)\n",
    "    canvas.image10 = im_out10\n",
    "    \n",
    "    plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo7.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out7 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo7.png')\n",
    "    canvas.create_image(1200,650,image=im_out7,anchor=NW)\n",
    "    canvas.image7 = im_out7\n",
    "    \n",
    "    radius = 5\n",
    "    i = canvas.create_oval(x_coord-radius, y_coord-radius, x_coord+radius, y_coord+radius, fill = 'red')\n",
    "    canvas.after(20,canvas.delete,i)\n",
    "\n",
    "# insert button to the middleframe and link it to \"Start Mouseover\"\n",
    "button_start_mouseover = Button(buttonframe, text=\"Start Mouseover\",command=start_mouseover)\n",
    "button_start_mouseover.grid(row=1, column=0, pady=0)\n",
    "\n",
    "\n",
    "root.mainloop()  #keep the GUI open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
