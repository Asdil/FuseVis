{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models.vgg import vgg19\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from skimage import img_as_ubyte\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision      # dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "import argparse\n",
    "import glob\n",
    "import imageio\n",
    "from skimage import color\n",
    "import numpy\n",
    "import natsort\n",
    "import scipy\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "import pprint\n",
    "from scipy.ndimage import correlate\n",
    "from scipy.ndimage.filters import gaussian_gradient_magnitude\n",
    "import torchvision.datasets as dset\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import os.path\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import tkinter.font as tkFont\n",
    "from PIL import ImageTk, Image\n",
    "import pylab\n",
    "import cv2\n",
    "import h5py\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(torch.cuda.get_device_properties(0).total_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the hyperparameters\n",
    "image_length = 256\n",
    "image_width  = 256\n",
    "mr_channels  = 1\n",
    "gray_channels = 1\n",
    "pet_channels = 4    \n",
    "rgb_channels = 3     \n",
    "batch_size   = 2\n",
    "EPOCH = 50\n",
    "learning_rate = 0.002 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the train mri data\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/Training/MRI')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/Training/MRI')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "train_mri = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    train_mri[i,:,:] =(imageio.imread(data[i]))\n",
    "    train_mri[i,:,:] =(train_mri[i,:,:] - np.min(train_mri[i,:,:])) / (np.max(train_mri[i,:,:]) - np.min(train_mri[i,:,:]))\n",
    "    train_mri[i,:,:] = np.float32(train_mri[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "train_mri = np.expand_dims(train_mri,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the shape matches the pytorch standard\n",
    "train_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the MRI training data to pytorch tensor\n",
    "train_mri_tensor = torch.from_numpy(train_mri).float()\n",
    "train_mri_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the train pet data\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/Training/PET')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/Training/PET')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "train_other = np.zeros((len(data),image_width,image_length,pet_channels),dtype=float)\n",
    "train_pet = np.zeros((len(data),image_width,image_length),dtype=float)\n",
    "for i in range(len(data)):\n",
    "    train_other[i,:,:,:] =(imageio.imread(data[i]))\n",
    "    train_pet[i,:,:] = 0.2989 * train_other[i,:,:,0] + 0.5870 *  train_other[i,:,:,1]  + 0.1140 * train_other[i,:,:,2]\n",
    "    train_pet[i,:,:] =(train_pet[i,:,:] - np.min(train_pet[i,:,:])) / (np.max(train_pet[i,:,:]) - np.min(train_pet[i,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand the dimension to add the channel\n",
    "train_pet = np.expand_dims(train_pet,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the shape matches the pytorch standard\n",
    "train_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the PET training data to pytorch tensor\n",
    "train_pet_tensor = torch.from_numpy(train_pet).float()\n",
    "train_pet_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the network\n",
    "class FunFuseAn(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super(FunFuseAn, self).__init__()\n",
    "        #####mri lf layer 1#####\n",
    "        self.mri_lf = nn.Sequential( #input shape (,1,256,256)\n",
    "                         nn.Conv2d(in_channels=1, out_channels=16, kernel_size=9, stride=1, padding=4),\n",
    "                         nn.BatchNorm2d(16),\n",
    "                         nn.LeakyReLU(0.2,inplace=True)) #output shape (,16,256,256)   \n",
    "        #####mri hf layers#####\n",
    "        self.mri_hf = nn.Sequential(  #input shape (,1,256,256)\n",
    "                         nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size  = 3, stride= 1, padding = 1),\n",
    "                         nn.BatchNorm2d(16),\n",
    "                         nn.LeakyReLU(0.2,inplace=True),\n",
    "                         nn.Conv2d(in_channels  = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),\n",
    "                         nn.BatchNorm2d(32),\n",
    "                         nn.LeakyReLU(0.2,inplace=True),\n",
    "                         nn.Conv2d(in_channels  = 32, out_channels = 64, kernel_size  = 3, stride = 1, padding = 1),\n",
    "                         nn.BatchNorm2d(64),\n",
    "                         nn.LeakyReLU(0.2,inplace=True)) #output shape (,64,256,256)\n",
    "        #####pet lf layer 1#####\n",
    "        self.pet_lf = nn.Sequential( #input shape (,1,256,256)\n",
    "                         nn.Conv2d(in_channels=1, out_channels=16, kernel_size=7, stride=1, padding=3),\n",
    "                         nn.BatchNorm2d(16),\n",
    "                         nn.LeakyReLU(0.2,inplace=True)) #output shape (,16,256,256)   \n",
    "        #####pet hf layers#####\n",
    "        self.pet_hf = nn.Sequential(  #input shape (,1,256,256)\n",
    "                         nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size  = 5, stride= 1, padding = 2),\n",
    "                         nn.BatchNorm2d(16),\n",
    "                         nn.LeakyReLU(0.2,inplace=True),\n",
    "                         nn.Conv2d(in_channels  = 16, out_channels = 32, kernel_size = 5, stride = 1, padding = 2),\n",
    "                         nn.BatchNorm2d(32),\n",
    "                         nn.LeakyReLU(0.2,inplace=True),\n",
    "                         nn.Conv2d(in_channels  = 32, out_channels = 64, kernel_size  = 3, stride = 1, padding = 1),\n",
    "                         nn.BatchNorm2d(64),\n",
    "                         nn.LeakyReLU(0.2,inplace=True)) #output shape (,64,256,256)\n",
    "        #####reconstruction layer 1#####\n",
    "        self.recon1 = nn.Sequential(  #input shape (, 64, 256, 256)\n",
    "                          nn.Conv2d(in_channels  = 64,  out_channels = 32, kernel_size  = 5, stride = 1, padding = 2),\n",
    "                          nn.BatchNorm2d(32),\n",
    "                          nn.LeakyReLU(0.2,inplace=True),\n",
    "                          nn.Conv2d(in_channels  = 32, out_channels = 16, kernel_size  = 5, stride = 1, padding = 2),\n",
    "                          nn.BatchNorm2d(16),\n",
    "                          nn.LeakyReLU(0.2,inplace=True)) #output shape (,16, 256, 256)\n",
    "        \n",
    "        #####reconstruction layer 2#####\n",
    "        self.recon2 = nn.Sequential(      #input shape (,16, 256, 256)\n",
    "                            nn.Conv2d(in_channels  = 16, out_channels = 1, kernel_size  = 5, stride = 1, padding = 2))   #output shape (,1,256,256)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        #mri lf layer 1\n",
    "        x1 = self.mri_lf(x)\n",
    "        #mri hf layers\n",
    "        x2 = self.mri_hf(x)\n",
    "        #pet lf layer 1\n",
    "        y1 = self.pet_lf(y)\n",
    "        #pet hf layers\n",
    "        y2 = self.pet_hf(y)\n",
    "        #high frequency fusion layer\n",
    "        fuse_hf = x2 + y2\n",
    "        #reconstruction layer1\n",
    "        recon_hf = self.recon1(fuse_hf)\n",
    "        #low frequency fusion layer\n",
    "        fuse_lf = (x1 + y1 + recon_hf)/3\n",
    "        #reconstruction layer2\n",
    "        recon3 = self.recon2(fuse_lf)\n",
    "        #tanh layer\n",
    "        fused = torch.tanh(recon3)      \n",
    "        return fused\n",
    "        #execute the network\n",
    "\n",
    "cnn = FunFuseAn().to(device)\n",
    "cnn = cnn.float()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the optimizers and loss functions \n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
    "l2_loss   = nn.MSELoss() #MSEloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the training\n",
    "counter = 0\n",
    "start_time = time.time()\n",
    "lamda = 0.8\n",
    "for epoch in range(EPOCH):\n",
    "  #run batch images\n",
    "  batch_idxs = 272 // batch_size\n",
    "  for idx in range(0, batch_idxs):\n",
    "    b_x = train_mri_tensor[idx*batch_size : (idx+1)*batch_size,:,:,:].to(device)\n",
    "    b_y = train_pet_tensor[idx*batch_size : (idx+1)*batch_size,:,:,:].to(device)\n",
    "    counter += 1\n",
    "    output = cnn(b_x,b_y)               # cnn output\n",
    "    ssim_loss_mri = 1 - ssim(output, b_x,data_range=1)\n",
    "    ssim_loss_pet = 1 - ssim(output, b_y,data_range=1)\n",
    "    ssim_total = ssim_loss_mri + ssim_loss_pet\n",
    "    l2_total = l2_loss(output,b_x) + l2_loss(output,b_y)\n",
    "    loss_total = lamda*ssim_total + (1-lamda)*l2_total \n",
    "    optimizer.zero_grad()           # clear gradients for this training step\n",
    "    loss_total.backward()           # backpropagation, compute gradients\n",
    "    optimizer.step()                # apply gradients\n",
    "    if counter % 100 == 0:\n",
    "      print(\"Epoch: [%2d],step: [%2d], mri_ssim_loss: [%.8f], pet_ssim_loss: [%.8f],  total_ssim_loss: [%.8f], total_l2_loss: [%.8f], total_loss: [%.8f]\" \n",
    "            %(epoch, counter, ssim_loss_mri, ssim_loss_pet, ssim_total, l2_total, loss_total))\n",
    "\n",
    "    if(epoch == EPOCH -1):\n",
    "      #Save a checkpoint\n",
    "      torch.save(cnn, 'C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/FunFuseAn/checkpoint.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test input MRI dataset\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/MRI/')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/MRI/')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "test_mri = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    test_mri[i,:,:] =(imageio.imread(data[i]))\n",
    "    test_mri[i,:,:] =(test_mri[i,:,:] - np.min(test_mri[i,:,:])) / (np.max(test_mri[i,:,:]) - np.min(test_mri[i,:,:]))\n",
    "    test_mri[i,:,:] = np.float32(test_mri[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "test_mri = np.expand_dims(test_mri,axis=1)\n",
    "#verify the shape matches the pytorch standard\n",
    "test_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the test mri image\n",
    "#test_mri = test_mri[0,:,:,:]\n",
    "#test_mri = np.expand_dims(test_mri,axis=0)\n",
    "plt.imshow(test_mri[0,0,:,:],'gray')\n",
    "#plt.savefig('MRI.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the MRI Testing data to pytorch tensor\n",
    "test_mri_tensor = torch.from_numpy(test_mri).float()\n",
    "print(test_mri_tensor.shape)\n",
    "test_mri_tensor.requires_grad =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test input PET dataset\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/PET/')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/PET/')\n",
    "data = glob.glob(os.path.join(dataset, \"*.png\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "test_pet = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    test_pet[i,:,:] =(imageio.imread(data[i]))\n",
    "    test_pet[i,:,:] =(test_pet[i,:,:] - np.min(test_pet[i,:,:])) / (np.max(test_pet[i,:,:]) - np.min(test_pet[i,:,:]))\n",
    "    test_pet[i,:,:] = np.float32(test_pet[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "test_pet = np.expand_dims(test_pet,axis=1)\n",
    "#verify the shape matches the pytorch standard\n",
    "test_pet.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the test pet image\n",
    "#test_pet = test_pet[2,:,:,:]\n",
    "#test_pet = np.expand_dims(test_pet,axis=0)\n",
    "plt.imshow(test_pet[0,0,:,:],'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_pet[0,0,:,:],'gray')\n",
    "#plt.savefig('PET.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the MRI Testing data to pytorch tensor\n",
    "test_pet_tensor = torch.from_numpy(test_pet).float()\n",
    "print(test_pet_tensor.shape)\n",
    "test_pet_tensor.requires_grad =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn =torch.load('C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/FunFuseAn/checkpoint.pth')\n",
    "cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted the fused image\n",
    "fused = cnn(test_mri_tensor.to(device), test_pet_tensor.to(device))\n",
    "fused_numpy = fused.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the output image\n",
    "plt.imshow(fused_numpy[0,0,:,:],'gray')\n",
    "#plt.savefig('Fused.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imageio.imwrite('C:/Users/horan/Desktop/Suraka/Fused/Fused.png',np.uint8(cv2.normalize(fused_numpy[0,0,:,:], None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the guidance image for MRI and PET wrt to the fused image\n",
    "time1 = time.time()\n",
    "count = 0 \n",
    "guide_fuse_mri = np.zeros((256,256),dtype=float)\n",
    "guide_fuse_pet = np.zeros((256,256),dtype=float)\n",
    "\n",
    "for y_coord in range(0,256):\n",
    "    for x_coord in range(0,256):\n",
    "        jacob_fuse_mri = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_mri_tensor, retain_graph=True, create_graph=True)[0]\n",
    "        jacob_numpy_mri = np.squeeze(jacob_fuse_mri.data.cpu().numpy())  \n",
    "        guide_fuse_mri[y_coord,x_coord] = jacob_numpy_mri[y_coord,x_coord]\n",
    "        jacob_fuse_pet = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_pet_tensor, retain_graph=True, create_graph=True)[0]\n",
    "        jacob_numpy_pet = np.squeeze(jacob_fuse_pet.data.cpu().numpy())  \n",
    "        guide_fuse_pet[y_coord,x_coord] = jacob_numpy_pet[y_coord,x_coord]\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print('Count is %d' %count)\n",
    "time2 = time.time()\n",
    "print('Time taken to compute is %d seconds' %(time2-time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "plt.colorbar()\n",
    "#plt.savefig('Jacob_Fused_MRI.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guide_fuse_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "#plt.colorbar()\n",
    "#plt.savefig('Jacob_Fused_PET.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guide_fuse_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(fused_RGB)\n",
    "#plt.savefig('Fused_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(mri_RGB)\n",
    "#plt.savefig('MRI_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(pet_RGB)\n",
    "#plt.savefig('PET_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5f = h5py.File('C:/Users/horan/Desktop/Suraka/Jacobian_MRI.h5', 'w')\n",
    "#h5f.create_dataset('MRI_dataset', data=guide_fuse_mri)\n",
    "#h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5f = h5py.File('C:/Users/horan/Desktop/Suraka/Jacobian_PET.h5', 'w')\n",
    "#h5f.create_dataset('PET_dataset', data=guide_fuse_pet)\n",
    "#h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/H5 Files/Jacobian_MRI.h5', 'r')\n",
    "guide_fuse_mri =  np.array(hf.get('MRI_dataset'))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/H5 Files/Jacobian_PET.h5', 'r')\n",
    "guide_fuse_pet =  np.array(hf.get('PET_dataset'))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define overlay images\n",
    "fused_RGB = np.zeros((256,256,3),dtype=float)\n",
    "mri_RGB   = np.zeros((256,256,3),dtype=float)\n",
    "pet_RGB   = np.zeros((256,256,3),dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_RGB[:,:,0]  = guide_fuse_mri \n",
    "fused_RGB[:,:,1]  = guide_fuse_pet \n",
    "fused_RGB[:,:,2]  = fused_numpy[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fused_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_RGB[:,:,0]  = guide_fuse_mri\n",
    "mri_RGB[:,:,1]  = guide_fuse_pet \n",
    "mri_RGB[:,:,2]  = test_mri[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mri_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_RGB[:,:,0]  = guide_fuse_mri\n",
    "pet_RGB[:,:,1]  = guide_fuse_pet \n",
    "pet_RGB[:,:,2]  = test_pet[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pet_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the window\n",
    "root = Tk()  \n",
    "root.title('Visualisation of fusion networks')\n",
    "root.configure(background='white')\n",
    "\n",
    "\n",
    "#Label the images\n",
    "#fontStyle = tkFont.Font(family=\"Lucida Grande\", size=15)\n",
    "#w1 = tk.Label(root, bg='white', font=fontStyle, text=\"Fused Image\")\n",
    "#w1.grid(row=0, column=1)\n",
    "#w1.pack()\n",
    "\n",
    "#define the frame\n",
    "canvasframe = Frame(root)  # define Input and output frame\n",
    "buttonframe = Frame(root)  # define button frame\n",
    "canvasframe.pack()  # pack the Input and Output frame\n",
    "buttonframe.pack()  # pack the button frame\n",
    "\n",
    "\n",
    "#define the canvas\n",
    "canvas = Canvas(canvasframe, width=1800, height=920, bg = 'white')\n",
    "canvas.grid(row=0, column=0)\n",
    "\n",
    "#Insert fused image to the canvas\n",
    "img_fused = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/Fused/Fused.png\") # load the image\n",
    "canvas.create_image(0, 0, image=img_fused, anchor=NW)\n",
    "\n",
    "#Insert MRI image to the canvas\n",
    "img_mri = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/MRI/MRI.gif\") # load the image\n",
    "canvas.create_image(620, 0, image=img_mri, anchor=NW)\n",
    "\n",
    "#Insert PET image to the canvas\n",
    "img_pet = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/PET/3.png\") # load the image\n",
    "canvas.create_image(1240, 0, image=img_pet, anchor=NW)\n",
    "\n",
    "def start_mouseover():  # function called when user clicks the button \n",
    "    # link the function to the left-mouse-click event\n",
    "    canvas.bind(\"<B1-Motion>\", Coordinates)\n",
    "\n",
    "def Coordinates(event): # function called when left-mouse-button is clicked with a mouseover\n",
    "    x_coord = event.x  # save x and y coordinates selected by the user   \n",
    "    y_coord = event.y\n",
    "    print('mouse position is at' + '(' + str(y_coord) + ',' + str(x_coord) + ')', end='\\r')\n",
    "    #display the output MRI Jacobian image\n",
    "    #img_MR_out = ImageTk.PhotoImage(file ='C:/Users/cgvadmin/Desktop/Suraka/Fused_MRI/im_' + str(y_coord) + '_' + str(x_coord) + '.png') # load the image\n",
    "    jacobian_fuse_mri = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_mri_tensor, retain_graph=True, create_graph=True)[0]\n",
    "    jacobian_fuse_pet = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_pet_tensor, retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    jacob_val_mri = np.squeeze(jacobian_fuse_mri.data.cpu().numpy())    \n",
    "    jacob_val_pet = np.squeeze(jacobian_fuse_pet.data.cpu().numpy())\n",
    "    \n",
    "    x_mri = np.asarray(np.where(np.any(jacob_val_mri, axis = 0)))\n",
    "    y_mri = np.asarray(np.where(np.any(jacob_val_mri, axis = 1)))\n",
    "    minx_mri, maxx_mri, miny_mri, maxy_mri = np.min(x_mri), np.max(x_mri), np.min(y_mri), np.max(y_mri)  #return min and max coordinates\n",
    "    zoom_im_mri = jacob_val_mri[miny_mri:maxy_mri,minx_mri:maxx_mri] \n",
    "    \n",
    "    x_pet = np.asarray(np.where(np.any(jacob_val_pet, axis = 0)))\n",
    "    y_pet = np.asarray(np.where(np.any(jacob_val_pet, axis = 1)))\n",
    "    minx_pet, maxx_pet, miny_pet, maxy_pet = np.min(x_pet), np.max(x_pet), np.min(y_pet), np.max(y_pet)  #return min and max coordinates\n",
    "    zoom_im_pet = jacob_val_pet[miny_pet:maxy_pet,minx_pet:maxx_pet] \n",
    "    \n",
    "    plt.imshow(fused_numpy[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom Fused')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo11.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out11 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo11.png')\n",
    "    canvas.create_image(320,0,image=im_out11,anchor=NW)\n",
    "    canvas.image11 = im_out11\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(test_mri[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom MRI')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo12.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out12 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo12.png')\n",
    "    canvas.create_image(950,0,image=im_out12,anchor=NW)\n",
    "    canvas.image12 = im_out12\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(test_pet[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom PET')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo13.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out13 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo13.png')\n",
    "    canvas.create_image(1500,0,image=im_out13,anchor=NW)\n",
    "    canvas.image13 = im_out13\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(jacob_val_mri,cmap='viridis', aspect ='equal')\n",
    "    plt.title('Fused wrt MRI')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo1.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out1 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo1.png')\n",
    "    canvas.create_image(0,320,image=im_out1,anchor=NW)\n",
    "    canvas.image1 = im_out1\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    #f.add_subplot(1,5,2)\n",
    "    plt.imshow(zoom_im_mri,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Zoomed (Fused wrt MRI)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo2.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out2 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo2.png')\n",
    "    canvas.create_image(280,320,image=im_out2,anchor=NW)\n",
    "    canvas.image2 = im_out2\n",
    "    #plt.tight_layout()\n",
    "    #divider = make_axes_locatable(plt)\n",
    "    #cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    #plt.colorbar(cax=cax)\n",
    "    \n",
    "    #f.add_subplot(1,5,3)\n",
    "    plt.xlim(0,0.7)\n",
    "    plt.ylim(0,0.7)\n",
    "    plt.plot(jacob_val_mri[y_coord,x_coord],jacob_val_pet[y_coord,x_coord],'-ro')\n",
    "    plt.xlabel('MRI pixel score (Fused wrt MRI)')\n",
    "    plt.ylabel('PET pixel score (Fused wrt PET)')\n",
    "    plt.title('Mouse position at: (' + str(y_coord) + ',' + str(x_coord) + ')')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.draw()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo3.png', bbox_inches = 'tight',pad_inches = 0.1)\n",
    "    plt.close()\n",
    "    im_out3 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo3.png')\n",
    "    canvas.create_image(600,320,image=im_out3,anchor=NW)\n",
    "    canvas.image3 = im_out3\n",
    "    \n",
    "    #f.add_subplot(1,5,4)\n",
    "    plt.imshow(jacob_val_pet,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Fused wrt PET')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo4.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out4 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo4.png')\n",
    "    canvas.create_image(900,320,image=im_out4,anchor=NW)\n",
    "    canvas.image4 = im_out4\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    #f.add_subplot(1,5,5)\n",
    "    plt.imshow(zoom_im_pet,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Zoomed (Fused wrt PET)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo5.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out5 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo5.png')\n",
    "    canvas.create_image(1180,320,image=im_out5,anchor=NW)\n",
    "    canvas.image5 = im_out5\n",
    "\n",
    "    plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "    plt.title('Fused wrt MRI')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo6.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out6 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo6.png')\n",
    "    canvas.create_image(0,650,image=im_out6,anchor=NW)\n",
    "    canvas.image6 = im_out6\n",
    "    \n",
    "    plt.imshow(fused_RGB)\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo8.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out8 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo8.png')\n",
    "    canvas.create_image(300,650,image=im_out8,anchor=NW)\n",
    "    canvas.image8 = im_out8\n",
    "    \n",
    "    plt.imshow(mri_RGB)\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo9.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out9 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo9.png')\n",
    "    canvas.create_image(600,650,image=im_out9,anchor=NW)\n",
    "    canvas.image9 = im_out9\n",
    "    \n",
    "    plt.imshow(pet_RGB)\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo10.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out10 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo10.png')\n",
    "    canvas.create_image(900,650,image=im_out10,anchor=NW)\n",
    "    canvas.image10 = im_out10\n",
    "    \n",
    "    plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo7.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out7 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo7.png')\n",
    "    canvas.create_image(1200,650,image=im_out7,anchor=NW)\n",
    "    canvas.image7 = im_out7\n",
    "    \n",
    "    radius = 5\n",
    "    i = canvas.create_oval(x_coord-radius, y_coord-radius, x_coord+radius, y_coord+radius, fill = 'red')\n",
    "    canvas.after(20,canvas.delete,i)\n",
    "\n",
    "# insert button to the middleframe and link it to \"Start Mouseover\"\n",
    "button_start_mouseover = Button(buttonframe, text=\"Start Mouseover\",command=start_mouseover)\n",
    "button_start_mouseover.grid(row=1, column=0, pady=0)\n",
    "\n",
    "\n",
    "root.mainloop()  #keep the GUI open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
