{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.models.vgg import vgg19\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from skimage import img_as_ubyte\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision      # dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "import argparse\n",
    "import glob\n",
    "import imageio\n",
    "from skimage import color\n",
    "import numpy\n",
    "import natsort\n",
    "import scipy\n",
    "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM\n",
    "import pprint\n",
    "from scipy.ndimage import correlate\n",
    "from scipy.ndimage.filters import gaussian_gradient_magnitude\n",
    "import torchvision.datasets as dset\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import os.path\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import tkinter.font as tkFont\n",
    "from PIL import ImageTk, Image\n",
    "import pylab\n",
    "import cv2\n",
    "import h5py\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(torch.cuda.get_device_properties(0).total_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the hyperparameters\n",
    "image_length = 256\n",
    "image_width  = 256\n",
    "mr_channels  = 1\n",
    "gray_channels = 1\n",
    "pet_channels = 4    \n",
    "rgb_channels = 3     \n",
    "batch_size   = 1\n",
    "EPOCH = 50\n",
    "learning_rate = 0.002 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the train mri data\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/Training/MRI')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/Training/MRI')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "train_mri = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    train_mri[i,:,:] =(imageio.imread(data[i]))\n",
    "    train_mri[i,:,:] =(train_mri[i,:,:] - np.min(train_mri[i,:,:])) / (np.max(train_mri[i,:,:]) - np.min(train_mri[i,:,:]))\n",
    "    train_mri[i,:,:] = np.float32(train_mri[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "train_mri = np.expand_dims(train_mri,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the shape matches the pytorch standard\n",
    "train_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the MRI training data to pytorch tensor\n",
    "train_mri_tensor = torch.from_numpy(train_mri).float()\n",
    "train_mri_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the train pet data\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/Training/PET')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/Training/PET')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "train_other = np.zeros((len(data),image_width,image_length,pet_channels),dtype=float)\n",
    "train_pet = np.zeros((len(data),image_width,image_length),dtype=float)\n",
    "for i in range(len(data)):\n",
    "    train_other[i,:,:,:] =(imageio.imread(data[i]))\n",
    "    train_pet[i,:,:] = 0.2989 * train_other[i,:,:,0] + 0.5870 *  train_other[i,:,:,1]  + 0.1140 * train_other[i,:,:,2]\n",
    "    train_pet[i,:,:] =(train_pet[i,:,:] - np.min(train_pet[i,:,:])) / (np.max(train_pet[i,:,:]) - np.min(train_pet[i,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand the dimension to add the channel\n",
    "train_pet = np.expand_dims(train_pet,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the shape matches the pytorch standard\n",
    "train_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the PET training data to pytorch tensor\n",
    "train_pet_tensor = torch.from_numpy(train_pet).float()\n",
    "train_pet_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the generator network\n",
    "class Generator(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        #####Layer 1#####\n",
    "        self.gen_layer1 = nn.Sequential( #input shape (,2,256,256)\n",
    "                         nn.Conv2d(in_channels=2, out_channels=256, kernel_size=5, stride=1, padding=2),\n",
    "                         nn.BatchNorm2d(256),\n",
    "                         nn.LeakyReLU(0.2,inplace=True)) #output shape (,256,256,256)   \n",
    "        #####Layer 2#####\n",
    "        self.gen_layer2 = nn.Sequential( #input shape (,256,256,256)\n",
    "                         nn.Conv2d(in_channels=256, out_channels=128, kernel_size=5, stride=1, padding=2),\n",
    "                         nn.BatchNorm2d(128),\n",
    "                         nn.LeakyReLU(0.2,inplace=True)) #output shape (,128,256,256)   \n",
    "        #####Layer 3#####\n",
    "        self.gen_layer3 = nn.Sequential( #input shape (,128,256,256)\n",
    "                         nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.BatchNorm2d(64),\n",
    "                         nn.LeakyReLU(0.2,inplace=True)) #output shape (,64,256,256)   \n",
    "        #####Layer 4#####\n",
    "        self.gen_layer4 = nn.Sequential( #input shape (,64,256,256)\n",
    "                         nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                         nn.BatchNorm2d(32),\n",
    "                         nn.LeakyReLU(0.2,inplace=True)) #output shape (,32,256,256)  \n",
    "        #####Layer 5#####\n",
    "        self.gen_layer5 = nn.Sequential( #input shape (,32,256,256)\n",
    "                         nn.Conv2d(in_channels=32, out_channels=1, kernel_size=1, stride=1))  #output shape (,1,256,256)  \n",
    "\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        #concat the input images\n",
    "        concat = torch.cat((x,y),1)\n",
    "        #layer 1\n",
    "        x1 = self.gen_layer1(concat)\n",
    "        #layer 2\n",
    "        x2 = self.gen_layer2(x1)\n",
    "        #layer 3\n",
    "        x3 = self.gen_layer3(x2)\n",
    "        #layer 4\n",
    "        x4 = self.gen_layer4(x3)\n",
    "        #layer 5\n",
    "        x5 = self.gen_layer5(x4)\n",
    "        #tanh layer\n",
    "        fused = torch.tanh(x5)      \n",
    "        return fused\n",
    "\n",
    "gen = Generator().to(device)\n",
    "gen = gen.float()\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the generator network\n",
    "class Discriminator(nn.Module):\n",
    "    def  __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        #####Layer 1#####\n",
    "        self.disc_layer1 = nn.Sequential( #input shape (,1,256,256)\n",
    "                         nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2),\n",
    "                         nn.LeakyReLU(0.2,inplace=True))   \n",
    "        #####Layer 2#####\n",
    "        self.disc_layer2 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2),\n",
    "                         nn.BatchNorm2d(64),\n",
    "                         nn.LeakyReLU(0.2,inplace=True)) \n",
    "        #####Layer 3#####\n",
    "        self.disc_layer3 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2),\n",
    "                         nn.BatchNorm2d(128),            \n",
    "                         nn.LeakyReLU(0.2,inplace=True))   \n",
    "        #####Layer 4#####\n",
    "        self.disc_layer4 = nn.Sequential( \n",
    "                         nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2),\n",
    "                         nn.BatchNorm2d(256),\n",
    "                         nn.LeakyReLU(0.2,inplace=True))   \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #layer 1\n",
    "        x1 = self.disc_layer1(x)\n",
    "        #layer 2\n",
    "        x2 = self.disc_layer2(x1)\n",
    "        #layer 3\n",
    "        x3 = self.disc_layer3(x2)\n",
    "        #layer 4\n",
    "        x4 = self.disc_layer4(x3)\n",
    "        #flatten the output\n",
    "        x5 = torch.flatten(x4, start_dim=1)\n",
    "        #print(x5.size())\n",
    "        #linear layer\n",
    "        lin = torch.nn.Linear(57600,1).to(device)  \n",
    "        score = lin(x5)\n",
    "        return score\n",
    "\n",
    "disc = Discriminator().to(device)\n",
    "disc = disc.float()\n",
    "print(disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the optimizers and loss functions \n",
    "gen_optimizer = torch.optim.Adam(gen.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
    "disc_optimizer = torch.optim.Adam(disc.parameters(), lr=learning_rate)   # optimize all cnn parameters\n",
    "l2_loss   = nn.MSELoss() #MSEloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the training\n",
    "counter = 0\n",
    "Tensor = torch.cuda.FloatTensor if device else torch.FloatTensor\n",
    "# Adversarial ground truths\n",
    "valid = Tensor([1,1])\n",
    "fake = Tensor([0,0])\n",
    "start_time = time.time()\n",
    "lamda = 1\n",
    "ep_ssim_mri_loss = []\n",
    "ep_ssim_pet_loss = []\n",
    "ep_adv_loss = []\n",
    "ep_disc_loss = []\n",
    "ep_gen_loss =[]\n",
    "for epoch in range(EPOCH):\n",
    "    ssim_mri_Loss = []\n",
    "    ssim_pet_Loss   = []\n",
    "    adv_Loss = []\n",
    "    gen_Loss = []\n",
    "    disc_Loss = []\n",
    "    #run batch images\n",
    "    batch_idxs = 272 // batch_size\n",
    "    for idx in range(0, batch_idxs):\n",
    "        #ge tthe mri and pet batches\n",
    "        b_x = train_mri_tensor[idx*batch_size : (idx+1)*batch_size,:,:,:].to(device)\n",
    "        b_y = train_pet_tensor[idx*batch_size : (idx+1)*batch_size,:,:,:].to(device)\n",
    "        counter += 1\n",
    "        \n",
    "        #clear the generator gradients\n",
    "        gen_optimizer.zero_grad()    \n",
    "\n",
    "        #get a fused image from generator\n",
    "        output = gen(b_x,b_y)               # gen output\n",
    "        \n",
    "        #feed the fused image into the discriminator\n",
    "        fused_disc_score = disc(output)\n",
    "        \n",
    "        #define the generator loss\n",
    "        ssim_loss_mri = 1 - ssim(output, b_x,data_range=1)\n",
    "        ssim_loss_pet = 1 - ssim(output, b_y,data_range=1)\n",
    "        ssim_loss = ssim_loss_mri + ssim_loss_pet\n",
    "        adv_loss = l2_loss(fused_disc_score,valid) \n",
    "        gen_loss = ssim_loss + adv_loss \n",
    "        \n",
    "        #update the generator\n",
    "        gen_loss.backward(retain_graph=True)                 # backpropagation, compute gradients\n",
    "        gen_optimizer.step()                # apply gradients\n",
    "        \n",
    "        #clear the discriminator gradients\n",
    "        disc_optimizer.zero_grad()           \n",
    "        \n",
    "        #feed the MRI image into the discriminator\n",
    "        mri_disc_score = disc(b_x.detach())\n",
    "        \n",
    "        #define the discriminator loss\n",
    "        disc_loss = l2_loss(fused_disc_score, fake) + l2_loss(mri_disc_score, valid)\n",
    "        \n",
    "        #update the discriminator\n",
    "        disc_loss.backward()                 # backpropagation, compute gradients\n",
    "        disc_optimizer.step()                # apply gradients  \n",
    "\n",
    "        #store all the loss values at each epoch\n",
    "        ssim_mri_Loss.append(ssim_loss_mri.item())\n",
    "        ssim_pet_Loss.append(ssim_loss_pet.item())\n",
    "        adv_Loss.append(adv_loss.item())\n",
    "        gen_Loss.append(gen_loss.item())\n",
    "        disc_Loss.append(disc_loss.item())\n",
    "        if counter % 100 == 0:\n",
    "            print(\"Epoch: [%2d],step: [%2d], mri_ssim_loss: [%.8f], pet_ssim_loss: [%.8f],  adv_loss: [%.8f], gen_loss: [%.8f], disc_loss: [%.8f]\" \n",
    "            %(epoch, counter, ssim_loss_mri, ssim_loss_pet, adv_loss, gen_loss, disc_loss))\n",
    "    \n",
    "    av_ssim_mri_loss = np.average(ssim_mri_Loss)\n",
    "    ep_ssim_mri_loss.append(av_ssim_mri_loss)\n",
    "    \n",
    "    av_ssim_pet_loss = np.average(ssim_pet_Loss)\n",
    "    ep_ssim_pet_loss.append(av_ssim_pet_loss)\n",
    "    \n",
    "    av_adv_loss = np.average(adv_Loss)\n",
    "    ep_adv_loss.append(av_adv_loss)\n",
    "    \n",
    "    av_gen_loss = np.average(gen_Loss)\n",
    "    ep_gen_loss.append(av_gen_loss)\n",
    "    \n",
    "    av_disc_loss = np.average(disc_Loss)\n",
    "    ep_disc_loss.append(av_disc_loss)\n",
    "    \n",
    "    if(epoch == EPOCH -1):\n",
    "        #Save a checkpoint\n",
    "        torch.save(gen, 'C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/FusionGAN/checkpoint_gen.pth') \n",
    "        torch.save(disc, 'C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/FusionGAN/checkpoint_disc.pth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = np.asarray(ep_ssim_mri_loss)\n",
    "l2 = np.asarray(ep_ssim_pet_loss)\n",
    "l3 = np.asarray(ep_adv_loss)\n",
    "l4 = np.asarray(ep_gen_loss)\n",
    "l5 = np.asarray(ep_disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('C:/Users/horan/Desktop/Suraka/Loss curves/FusionGAN/H5 Files/Loss_DISC.h5', 'w')\n",
    "h5f.create_dataset('MRI_dataset', data=l5)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l5)\n",
    "#plt.savefig('C:/Users/horan/Desktop/Suraka/Loss curves/VIFNet/Loss curves/SSIM_MRI_loss_curve.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test input MRI dataset\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/MRI/')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/MRI/')\n",
    "data = glob.glob(os.path.join(dataset, \"*.gif\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "test_mri = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    test_mri[i,:,:] =(imageio.imread(data[i]))\n",
    "    test_mri[i,:,:] =(test_mri[i,:,:] - np.min(test_mri[i,:,:])) / (np.max(test_mri[i,:,:]) - np.min(test_mri[i,:,:]))\n",
    "    test_mri[i,:,:] = np.float32(test_mri[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "test_mri = np.expand_dims(test_mri,axis=1)\n",
    "#verify the shape matches the pytorch standard\n",
    "test_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the test mri image\n",
    "#test_mri = test_mri[0,:,:,:]\n",
    "#test_mri = np.expand_dims(test_mri,axis=0)\n",
    "plt.imshow(test_mri[0,0,:,:],'gray')\n",
    "#plt.savefig('MRI.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the MRI Testing data to pytorch tensor\n",
    "test_mri_tensor = torch.from_numpy(test_mri).float()\n",
    "print(test_mri_tensor.shape)\n",
    "test_mri_tensor.requires_grad =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test input PET dataset\n",
    "filenames = os.listdir('C:/Users/horan/Desktop/Suraka/PET/')\n",
    "dataset = os.path.join(os.getcwd(), 'C:/Users/horan/Desktop/Suraka/PET/')\n",
    "data = glob.glob(os.path.join(dataset, \"*.png\"))\n",
    "data = natsort.natsorted(data,reverse=False)\n",
    "test_pet = np.zeros((len(data), image_width,image_length))\n",
    "for i in range(len(data)):\n",
    "    test_pet[i,:,:] =(imageio.imread(data[i]))\n",
    "    test_pet[i,:,:] =(test_pet[i,:,:] - np.min(test_pet[i,:,:])) / (np.max(test_pet[i,:,:]) - np.min(test_pet[i,:,:]))\n",
    "    test_pet[i,:,:] = np.float32(test_pet[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#expand dimension to add the channel\n",
    "test_pet = np.expand_dims(test_pet,axis=1)\n",
    "#verify the shape matches the pytorch standard\n",
    "test_pet.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the test pet image\n",
    "#test_pet = test_pet[2,:,:,:]\n",
    "#test_pet = np.expand_dims(test_pet,axis=0)\n",
    "plt.imshow(test_pet[0,0,:,:],'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_pet[0,0,:,:],'gray')\n",
    "#plt.savefig('PET.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the MRI Testing data to pytorch tensor\n",
    "test_pet_tensor = torch.from_numpy(test_pet).float()\n",
    "print(test_pet_tensor.shape)\n",
    "test_pet_tensor.requires_grad =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gen =torch.load('C:/Users/horan/Desktop/Suraka/.ipynb_checkpoints/FusionGAN/checkpoint_gen.pth')\n",
    "gen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted the fused image\n",
    "fused = gen(test_mri_tensor.to(device), test_pet_tensor.to(device))\n",
    "fused_numpy = fused.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the output image\n",
    "plt.imshow(fused_numpy[0,0,:,:],'gray')\n",
    "#plt.savefig('Fused.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imageio.imwrite('C:/Users/horan/Desktop/Suraka/Fused/Fused.png',np.uint8(cv2.normalize(fused_numpy[0,0,:,:], None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the guidance image for MRI and PET wrt to the fused image\n",
    "time1 = time.time()\n",
    "count = 0 \n",
    "guide_fuse_mri = np.zeros((256,256),dtype=float)\n",
    "guide_fuse_pet = np.zeros((256,256),dtype=float)\n",
    "\n",
    "for y_coord in range(0,256):\n",
    "    for x_coord in range(0,256):\n",
    "        jacob_fuse_mri = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_mri_tensor, retain_graph=True, create_graph=True)[0]\n",
    "        jacob_numpy_mri = np.squeeze(jacob_fuse_mri.data.cpu().numpy())  \n",
    "        guide_fuse_mri[y_coord,x_coord] = jacob_numpy_mri[y_coord,x_coord]\n",
    "        jacob_fuse_pet = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_pet_tensor, retain_graph=True, create_graph=True)[0]\n",
    "        jacob_numpy_pet = np.squeeze(jacob_fuse_pet.data.cpu().numpy())  \n",
    "        guide_fuse_pet[y_coord,x_coord] = jacob_numpy_pet[y_coord,x_coord]\n",
    "        count += 1\n",
    "        if count % 100 == 0:\n",
    "            print('Count is %d' %count)\n",
    "time2 = time.time()\n",
    "print('Time taken to compute is %d seconds' %(time2-time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "plt.colorbar()\n",
    "#plt.savefig('Jacob_Fused_MRI.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guide_fuse_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "#plt.colorbar()\n",
    "#plt.savefig('Jacob_Fused_PET.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guide_fuse_pet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(fused_RGB)\n",
    "#plt.savefig('Fused_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(mri_RGB)\n",
    "#plt.savefig('MRI_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(pet_RGB)\n",
    "#plt.savefig('PET_RGB.png', bbox_inches = 'tight',pad_inches = 0,dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5f = h5py.File('C:/Users/horan/Desktop/Suraka/Jacobian_MRI.h5', 'w')\n",
    "#h5f.create_dataset('MRI_dataset', data=guide_fuse_mri)\n",
    "#h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5f = h5py.File('C:/Users/horan/Desktop/Suraka/Jacobian_PET.h5', 'w')\n",
    "#h5f.create_dataset('PET_dataset', data=guide_fuse_pet)\n",
    "#h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/H5 Files/Jacobian_MRI.h5', 'r')\n",
    "guide_fuse_mri =  np.array(hf.get('MRI_dataset'))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/H5 Files/Jacobian_PET.h5', 'r')\n",
    "guide_fuse_pet =  np.array(hf.get('PET_dataset'))\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define overlay images\n",
    "fused_RGB = np.zeros((256,256,3),dtype=float)\n",
    "mri_RGB   = np.zeros((256,256,3),dtype=float)\n",
    "pet_RGB   = np.zeros((256,256,3),dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_RGB[:,:,0]  = guide_fuse_mri \n",
    "fused_RGB[:,:,1]  = guide_fuse_pet \n",
    "fused_RGB[:,:,2]  = fused_numpy[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fused_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_RGB[:,:,0]  = guide_fuse_mri\n",
    "mri_RGB[:,:,1]  = guide_fuse_pet \n",
    "mri_RGB[:,:,2]  = test_mri[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mri_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_RGB[:,:,0]  = guide_fuse_mri\n",
    "pet_RGB[:,:,1]  = guide_fuse_pet \n",
    "pet_RGB[:,:,2]  = test_pet[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pet_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the window\n",
    "root = Tk()  \n",
    "root.title('Visualisation of fusion networks')\n",
    "root.configure(background='white')\n",
    "\n",
    "\n",
    "#Label the images\n",
    "#fontStyle = tkFont.Font(family=\"Lucida Grande\", size=15)\n",
    "#w1 = tk.Label(root, bg='white', font=fontStyle, text=\"Fused Image\")\n",
    "#w1.grid(row=0, column=1)\n",
    "#w1.pack()\n",
    "\n",
    "#define the frame\n",
    "canvasframe = Frame(root)  # define Input and output frame\n",
    "buttonframe = Frame(root)  # define button frame\n",
    "canvasframe.pack()  # pack the Input and Output frame\n",
    "buttonframe.pack()  # pack the button frame\n",
    "\n",
    "\n",
    "#define the canvas\n",
    "canvas = Canvas(canvasframe, width=1800, height=920, bg = 'white')\n",
    "canvas.grid(row=0, column=0)\n",
    "\n",
    "#Insert fused image to the canvas\n",
    "img_fused = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/Fused/Fused.png\") # load the image\n",
    "canvas.create_image(0, 0, image=img_fused, anchor=NW)\n",
    "\n",
    "#Insert MRI image to the canvas\n",
    "img_mri = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/MRI/MRI.gif\") # load the image\n",
    "canvas.create_image(620, 0, image=img_mri, anchor=NW)\n",
    "\n",
    "#Insert PET image to the canvas\n",
    "img_pet = ImageTk.PhotoImage(file =\"C:/Users/horan/Desktop/Suraka/PET/3.png\") # load the image\n",
    "canvas.create_image(1240, 0, image=img_pet, anchor=NW)\n",
    "\n",
    "def start_mouseover():  # function called when user clicks the button \n",
    "    # link the function to the left-mouse-click event\n",
    "    canvas.bind(\"<B1-Motion>\", Coordinates)\n",
    "\n",
    "def Coordinates(event): # function called when left-mouse-button is clicked with a mouseover\n",
    "    x_coord = event.x  # save x and y coordinates selected by the user   \n",
    "    y_coord = event.y\n",
    "    print('mouse position is at' + '(' + str(y_coord) + ',' + str(x_coord) + ')', end='\\r')\n",
    "    #display the output MRI Jacobian image\n",
    "    #img_MR_out = ImageTk.PhotoImage(file ='C:/Users/cgvadmin/Desktop/Suraka/Fused_MRI/im_' + str(y_coord) + '_' + str(x_coord) + '.png') # load the image\n",
    "    jacobian_fuse_mri = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_mri_tensor, retain_graph=True, create_graph=True)[0]\n",
    "    jacobian_fuse_pet = torch.autograd.grad(fused[0,0,y_coord,x_coord], test_pet_tensor, retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "    jacob_val_mri = np.squeeze(jacobian_fuse_mri.data.cpu().numpy())    \n",
    "    jacob_val_pet = np.squeeze(jacobian_fuse_pet.data.cpu().numpy())\n",
    "    \n",
    "    x_mri = np.asarray(np.where(np.any(jacob_val_mri, axis = 0)))\n",
    "    y_mri = np.asarray(np.where(np.any(jacob_val_mri, axis = 1)))\n",
    "    minx_mri, maxx_mri, miny_mri, maxy_mri = np.min(x_mri), np.max(x_mri), np.min(y_mri), np.max(y_mri)  #return min and max coordinates\n",
    "    zoom_im_mri = jacob_val_mri[miny_mri:maxy_mri,minx_mri:maxx_mri] \n",
    "    \n",
    "    x_pet = np.asarray(np.where(np.any(jacob_val_pet, axis = 0)))\n",
    "    y_pet = np.asarray(np.where(np.any(jacob_val_pet, axis = 1)))\n",
    "    minx_pet, maxx_pet, miny_pet, maxy_pet = np.min(x_pet), np.max(x_pet), np.min(y_pet), np.max(y_pet)  #return min and max coordinates\n",
    "    zoom_im_pet = jacob_val_pet[miny_pet:maxy_pet,minx_pet:maxx_pet] \n",
    "    \n",
    "    plt.imshow(fused_numpy[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom Fused')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo11.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out11 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo11.png')\n",
    "    canvas.create_image(320,0,image=im_out11,anchor=NW)\n",
    "    canvas.image11 = im_out11\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(test_mri[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom MRI')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo12.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out12 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo12.png')\n",
    "    canvas.create_image(950,0,image=im_out12,anchor=NW)\n",
    "    canvas.image12 = im_out12\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(test_pet[0,0,miny_mri:maxy_mri,minx_mri:maxx_mri], cmap = 'gray', aspect ='equal')\n",
    "    plt.title('Zoom PET')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo13.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out13 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo13.png')\n",
    "    canvas.create_image(1500,0,image=im_out13,anchor=NW)\n",
    "    canvas.image13 = im_out13\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.imshow(jacob_val_mri,cmap='viridis', aspect ='equal')\n",
    "    plt.title('Fused wrt MRI')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo1.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out1 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo1.png')\n",
    "    canvas.create_image(0,320,image=im_out1,anchor=NW)\n",
    "    canvas.image1 = im_out1\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    #f.add_subplot(1,5,2)\n",
    "    plt.imshow(zoom_im_mri,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Zoomed (Fused wrt MRI)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo2.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out2 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo2.png')\n",
    "    canvas.create_image(280,320,image=im_out2,anchor=NW)\n",
    "    canvas.image2 = im_out2\n",
    "    #plt.tight_layout()\n",
    "    #divider = make_axes_locatable(plt)\n",
    "    #cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    #plt.colorbar(cax=cax)\n",
    "    \n",
    "    #f.add_subplot(1,5,3)\n",
    "    plt.xlim(0,0.7)\n",
    "    plt.ylim(0,0.7)\n",
    "    plt.plot(jacob_val_mri[y_coord,x_coord],jacob_val_pet[y_coord,x_coord],'-ro')\n",
    "    plt.xlabel('MRI pixel score (Fused wrt MRI)')\n",
    "    plt.ylabel('PET pixel score (Fused wrt PET)')\n",
    "    plt.title('Mouse position at: (' + str(y_coord) + ',' + str(x_coord) + ')')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.draw()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo3.png', bbox_inches = 'tight',pad_inches = 0.1)\n",
    "    plt.close()\n",
    "    im_out3 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo3.png')\n",
    "    canvas.create_image(600,320,image=im_out3,anchor=NW)\n",
    "    canvas.image3 = im_out3\n",
    "    \n",
    "    #f.add_subplot(1,5,4)\n",
    "    plt.imshow(jacob_val_pet,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Fused wrt PET')\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo4.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out4 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo4.png')\n",
    "    canvas.create_image(900,320,image=im_out4,anchor=NW)\n",
    "    canvas.image4 = im_out4\n",
    "    #plt.tight_layout()\n",
    "    \n",
    "    #f.add_subplot(1,5,5)\n",
    "    plt.imshow(zoom_im_pet,cmap='viridis',aspect ='equal')\n",
    "    plt.title('Zoomed (Fused wrt PET)')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo5.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out5 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo5.png')\n",
    "    canvas.create_image(1180,320,image=im_out5,anchor=NW)\n",
    "    canvas.image5 = im_out5\n",
    "\n",
    "    plt.imshow(guide_fuse_mri,cmap='viridis')\n",
    "    plt.title('Fused wrt MRI')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo6.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out6 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo6.png')\n",
    "    canvas.create_image(0,650,image=im_out6,anchor=NW)\n",
    "    canvas.image6 = im_out6\n",
    "    \n",
    "    plt.imshow(fused_RGB)\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo8.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out8 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo8.png')\n",
    "    canvas.create_image(300,650,image=im_out8,anchor=NW)\n",
    "    canvas.image8 = im_out8\n",
    "    \n",
    "    plt.imshow(mri_RGB)\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo9.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out9 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo9.png')\n",
    "    canvas.create_image(600,650,image=im_out9,anchor=NW)\n",
    "    canvas.image9 = im_out9\n",
    "    \n",
    "    plt.imshow(pet_RGB)\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo10.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out10 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo10.png')\n",
    "    canvas.create_image(900,650,image=im_out10,anchor=NW)\n",
    "    canvas.image10 = im_out10\n",
    "    \n",
    "    plt.imshow(guide_fuse_pet,cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo7.png', bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close()\n",
    "    im_out7 = ImageTk.PhotoImage(file ='C:/Users/horan/Desktop/Suraka/Guidance images/FunFuseAn/Resultant images/foo7.png')\n",
    "    canvas.create_image(1200,650,image=im_out7,anchor=NW)\n",
    "    canvas.image7 = im_out7\n",
    "    \n",
    "    radius = 5\n",
    "    i = canvas.create_oval(x_coord-radius, y_coord-radius, x_coord+radius, y_coord+radius, fill = 'red')\n",
    "    canvas.after(20,canvas.delete,i)\n",
    "\n",
    "# insert button to the middleframe and link it to \"Start Mouseover\"\n",
    "button_start_mouseover = Button(buttonframe, text=\"Start Mouseover\",command=start_mouseover)\n",
    "button_start_mouseover.grid(row=1, column=0, pady=0)\n",
    "\n",
    "\n",
    "root.mainloop()  #keep the GUI open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
